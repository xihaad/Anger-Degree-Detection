{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOxmP1uskXTEGvzhIZG6PTS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQ9MQaj_omTa","executionInfo":{"status":"ok","timestamp":1663138318638,"user_tz":-360,"elapsed":3789,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"a5ee83ff-5e4b-4555-fb85-69da2266f89b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from imblearn.over_sampling import SMOTE\n","import os\n","import sys\n","\n","# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n","import librosa\n","import librosa.display\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","# to play the audio files\n","from IPython.display import Audio\n","\n","import keras\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n","from keras.utils import np_utils\n","from tensorflow.keras.utils import to_categorical\n","from keras.callbacks import ModelCheckpoint"],"metadata":{"id":"3K9J7x_Wp_3q","executionInfo":{"status":"ok","timestamp":1663138318639,"user_tz":-360,"elapsed":25,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, recall_score, precision_score\n","import math\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","# Importing the dataset\n","Features = pd.read_csv('/content/drive/MyDrive/DataMining/Datasets/Selected_Features.csv')\n","X = Features.iloc[: ,:-1].values\n","Y = Features['class'].values\n"],"metadata":{"id":"G0HwGeBnos6S","executionInfo":{"status":"ok","timestamp":1663138318639,"user_tz":-360,"elapsed":23,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# # As this is a multiclass classification problem onehotencoding our Y.\n","# encoder = OneHotEncoder()\n","# Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"],"metadata":{"id":"Kdsb7fnootj4","executionInfo":{"status":"ok","timestamp":1663138318639,"user_tz":-360,"elapsed":22,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# splitting data\n","# smote_on_1 = 212\n","# smote = SMOTE(sampling_strategy={'Minimal': smote_on_1,'Moderate': smote_on_1, 'Extreme': smote_on_1})\n","# X, Y = smote.fit_resample(X, Y)\n","encoder = OneHotEncoder()\n","Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xiO6IEvXpVqP","executionInfo":{"status":"ok","timestamp":1663138318640,"user_tz":-360,"elapsed":22,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"ff93772d-4c7f-4344-d382-1affd8a54a6a"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((503, 26), (503, 4), (168, 26), (168, 4))"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["# scaling our data with sklearn's Standard scaler\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QZ8JP-6vpgjE","executionInfo":{"status":"ok","timestamp":1663138318640,"user_tz":-360,"elapsed":20,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"baf75c9b-749a-45b6-9e10-9075c4f1cb18"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((503, 26), (503, 4), (168, 26), (168, 4))"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["# making our data compatible to model.\n","x_train = np.expand_dims(x_train, axis=2)\n","x_test = np.expand_dims(x_test, axis=2)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bw2ig4ASwoDj","executionInfo":{"status":"ok","timestamp":1663138318640,"user_tz":-360,"elapsed":18,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"55ab3092-0f72-4246-af97-e685f49270eb"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((503, 26, 1), (503, 4), (168, 26, 1), (168, 4))"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["# # # making our data compatible to model.\n","# # x_train = np.expand_dims(x_train, axis=2)\n","# # x_test = np.expand_dims(x_test, axis=2)\n","# y_train = np.expand_dims(y_train, axis=1)\n","# x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"metadata":{"id":"8xI2ttebpvH-","executionInfo":{"status":"ok","timestamp":1663138318640,"user_tz":-360,"elapsed":15,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n"],"metadata":{"id":"OSd_cSRyuQEV","executionInfo":{"status":"ok","timestamp":1663138318641,"user_tz":-360,"elapsed":16,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["model=Sequential()\n","model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n","# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n","# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n","# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n","# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n","model.add(Dropout(0.3))\n","\n","model.add(Flatten())\n","model.add(Dense(units=32, activation='relu'))\n","# model.add(Dropout(0.3))\n","\n","model.add(Dense(units=4, activation='softmax'))\n","model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeZgfNWNpyPt","executionInfo":{"status":"ok","timestamp":1663138318641,"user_tz":-360,"elapsed":16,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"b9f4f7a6-3bb4-4037-f5af-5ac447386a66"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d_8 (Conv1D)           (None, 26, 256)           1536      \n","                                                                 \n"," dropout_8 (Dropout)         (None, 26, 256)           0         \n","                                                                 \n"," conv1d_9 (Conv1D)           (None, 26, 256)           327936    \n","                                                                 \n"," dropout_9 (Dropout)         (None, 26, 256)           0         \n","                                                                 \n"," conv1d_10 (Conv1D)          (None, 26, 128)           163968    \n","                                                                 \n"," dropout_10 (Dropout)        (None, 26, 128)           0         \n","                                                                 \n"," conv1d_11 (Conv1D)          (None, 26, 64)            41024     \n","                                                                 \n"," dropout_11 (Dropout)        (None, 26, 64)            0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 1664)              0         \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                53280     \n","                                                                 \n"," dense_5 (Dense)             (None, 4)                 132       \n","                                                                 \n","=================================================================\n","Total params: 587,876\n","Trainable params: 587,876\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n","# history=model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[rlrp])\n","history=model.fit(x_train, y_train, batch_size=8, epochs=200, validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0eggGrvrvhh","outputId":"e2a3d158-1507-4895-caf8-3bb65ce60c7a","executionInfo":{"status":"ok","timestamp":1663138821520,"user_tz":-360,"elapsed":502886,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","63/63 [==============================] - 4s 44ms/step - loss: 1.2557 - accuracy: 0.4354 - val_loss: 1.2105 - val_accuracy: 0.4286\n","Epoch 2/200\n","63/63 [==============================] - 3s 44ms/step - loss: 1.1273 - accuracy: 0.4911 - val_loss: 1.1108 - val_accuracy: 0.4702\n","Epoch 3/200\n","63/63 [==============================] - 3s 55ms/step - loss: 1.0398 - accuracy: 0.5467 - val_loss: 1.0879 - val_accuracy: 0.4702\n","Epoch 4/200\n","63/63 [==============================] - 3s 42ms/step - loss: 1.0347 - accuracy: 0.5547 - val_loss: 1.0725 - val_accuracy: 0.5000\n","Epoch 5/200\n","63/63 [==============================] - 4s 60ms/step - loss: 0.9935 - accuracy: 0.5626 - val_loss: 1.0464 - val_accuracy: 0.5000\n","Epoch 6/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.9746 - accuracy: 0.5706 - val_loss: 1.1059 - val_accuracy: 0.4821\n","Epoch 7/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.9490 - accuracy: 0.6103 - val_loss: 1.0654 - val_accuracy: 0.4881\n","Epoch 8/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.9012 - accuracy: 0.6183 - val_loss: 1.0601 - val_accuracy: 0.5000\n","Epoch 9/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.9123 - accuracy: 0.6004 - val_loss: 1.0452 - val_accuracy: 0.4940\n","Epoch 10/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.8462 - accuracy: 0.6501 - val_loss: 1.1038 - val_accuracy: 0.4643\n","Epoch 11/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.8598 - accuracy: 0.6302 - val_loss: 1.1349 - val_accuracy: 0.5179\n","Epoch 12/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.8381 - accuracy: 0.6183 - val_loss: 1.0621 - val_accuracy: 0.5060\n","Epoch 13/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.7978 - accuracy: 0.6521 - val_loss: 1.0808 - val_accuracy: 0.4940\n","Epoch 14/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.7856 - accuracy: 0.6421 - val_loss: 1.0808 - val_accuracy: 0.4881\n","Epoch 15/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.7270 - accuracy: 0.6839 - val_loss: 1.2137 - val_accuracy: 0.4643\n","Epoch 16/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.7184 - accuracy: 0.6958 - val_loss: 1.1276 - val_accuracy: 0.5000\n","Epoch 17/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.6660 - accuracy: 0.7276 - val_loss: 1.2494 - val_accuracy: 0.4702\n","Epoch 18/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.6480 - accuracy: 0.7356 - val_loss: 1.3091 - val_accuracy: 0.4702\n","Epoch 19/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.6346 - accuracy: 0.7256 - val_loss: 1.2069 - val_accuracy: 0.4464\n","Epoch 20/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.5554 - accuracy: 0.7654 - val_loss: 1.4066 - val_accuracy: 0.4881\n","Epoch 21/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.5222 - accuracy: 0.7833 - val_loss: 1.4701 - val_accuracy: 0.4345\n","Epoch 22/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.5409 - accuracy: 0.7714 - val_loss: 1.2792 - val_accuracy: 0.4821\n","Epoch 23/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.5149 - accuracy: 0.7654 - val_loss: 1.3276 - val_accuracy: 0.4881\n","Epoch 24/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.4156 - accuracy: 0.8370 - val_loss: 1.4211 - val_accuracy: 0.5119\n","Epoch 25/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.4628 - accuracy: 0.8171 - val_loss: 1.5026 - val_accuracy: 0.5119\n","Epoch 26/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.4551 - accuracy: 0.8151 - val_loss: 1.4049 - val_accuracy: 0.5119\n","Epoch 27/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.3618 - accuracy: 0.8549 - val_loss: 1.6590 - val_accuracy: 0.4702\n","Epoch 28/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.3700 - accuracy: 0.8588 - val_loss: 1.7838 - val_accuracy: 0.4940\n","Epoch 29/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.3752 - accuracy: 0.8767 - val_loss: 1.8962 - val_accuracy: 0.4524\n","Epoch 30/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.4487 - accuracy: 0.8250 - val_loss: 1.5240 - val_accuracy: 0.4940\n","Epoch 31/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.3042 - accuracy: 0.8708 - val_loss: 1.8761 - val_accuracy: 0.5000\n","Epoch 32/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.3399 - accuracy: 0.8827 - val_loss: 1.8070 - val_accuracy: 0.5298\n","Epoch 33/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.2334 - accuracy: 0.9165 - val_loss: 2.1075 - val_accuracy: 0.4821\n","Epoch 34/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.3041 - accuracy: 0.8907 - val_loss: 2.0475 - val_accuracy: 0.4940\n","Epoch 35/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.2478 - accuracy: 0.8986 - val_loss: 1.9010 - val_accuracy: 0.4762\n","Epoch 36/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.3094 - accuracy: 0.9066 - val_loss: 1.7816 - val_accuracy: 0.5000\n","Epoch 37/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.2506 - accuracy: 0.9105 - val_loss: 2.2456 - val_accuracy: 0.5119\n","Epoch 38/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.2037 - accuracy: 0.9245 - val_loss: 2.2331 - val_accuracy: 0.5119\n","Epoch 39/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.2669 - accuracy: 0.9225 - val_loss: 1.9222 - val_accuracy: 0.5417\n","Epoch 40/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.2591 - accuracy: 0.9085 - val_loss: 2.3550 - val_accuracy: 0.4821\n","Epoch 41/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.2266 - accuracy: 0.9105 - val_loss: 2.1496 - val_accuracy: 0.5000\n","Epoch 42/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.1779 - accuracy: 0.9304 - val_loss: 2.3683 - val_accuracy: 0.5119\n","Epoch 43/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.2651 - accuracy: 0.9245 - val_loss: 1.9949 - val_accuracy: 0.5000\n","Epoch 44/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1975 - accuracy: 0.9284 - val_loss: 2.1687 - val_accuracy: 0.5060\n","Epoch 45/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1904 - accuracy: 0.9264 - val_loss: 2.2560 - val_accuracy: 0.5060\n","Epoch 46/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.1328 - accuracy: 0.9563 - val_loss: 2.4174 - val_accuracy: 0.5179\n","Epoch 47/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.1128 - accuracy: 0.9563 - val_loss: 2.6430 - val_accuracy: 0.5060\n","Epoch 48/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.2294 - accuracy: 0.9304 - val_loss: 2.5138 - val_accuracy: 0.4464\n","Epoch 49/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.1853 - accuracy: 0.9205 - val_loss: 2.7734 - val_accuracy: 0.4643\n","Epoch 50/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.1471 - accuracy: 0.9523 - val_loss: 2.2739 - val_accuracy: 0.5476\n","Epoch 51/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.1085 - accuracy: 0.9602 - val_loss: 2.7227 - val_accuracy: 0.5179\n","Epoch 52/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.1433 - accuracy: 0.9563 - val_loss: 3.0517 - val_accuracy: 0.5119\n","Epoch 53/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1863 - accuracy: 0.9443 - val_loss: 2.8235 - val_accuracy: 0.5060\n","Epoch 54/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.1617 - accuracy: 0.9443 - val_loss: 2.9124 - val_accuracy: 0.4821\n","Epoch 55/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.1601 - accuracy: 0.9443 - val_loss: 2.8500 - val_accuracy: 0.4643\n","Epoch 56/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.1414 - accuracy: 0.9443 - val_loss: 3.0600 - val_accuracy: 0.4940\n","Epoch 57/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.1333 - accuracy: 0.9503 - val_loss: 2.9595 - val_accuracy: 0.4881\n","Epoch 58/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.1498 - accuracy: 0.9543 - val_loss: 2.6006 - val_accuracy: 0.4940\n","Epoch 59/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1518 - accuracy: 0.9503 - val_loss: 2.8841 - val_accuracy: 0.4821\n","Epoch 60/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0899 - accuracy: 0.9702 - val_loss: 3.1377 - val_accuracy: 0.5000\n","Epoch 61/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1346 - accuracy: 0.9443 - val_loss: 2.9892 - val_accuracy: 0.4881\n","Epoch 62/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1489 - accuracy: 0.9483 - val_loss: 3.0616 - val_accuracy: 0.4643\n","Epoch 63/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0996 - accuracy: 0.9722 - val_loss: 3.3920 - val_accuracy: 0.5119\n","Epoch 64/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1697 - accuracy: 0.9483 - val_loss: 3.0119 - val_accuracy: 0.5060\n","Epoch 65/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1621 - accuracy: 0.9463 - val_loss: 3.3235 - val_accuracy: 0.4702\n","Epoch 66/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1396 - accuracy: 0.9523 - val_loss: 3.0624 - val_accuracy: 0.4821\n","Epoch 67/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.1527 - accuracy: 0.9384 - val_loss: 3.1545 - val_accuracy: 0.5000\n","Epoch 68/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1543 - accuracy: 0.9404 - val_loss: 2.9103 - val_accuracy: 0.4940\n","Epoch 69/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.2001 - accuracy: 0.9503 - val_loss: 2.6762 - val_accuracy: 0.5179\n","Epoch 70/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1443 - accuracy: 0.9662 - val_loss: 2.8715 - val_accuracy: 0.4940\n","Epoch 71/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.0967 - accuracy: 0.9742 - val_loss: 3.0191 - val_accuracy: 0.4881\n","Epoch 72/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0962 - accuracy: 0.9642 - val_loss: 3.2268 - val_accuracy: 0.4643\n","Epoch 73/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1060 - accuracy: 0.9563 - val_loss: 2.9329 - val_accuracy: 0.4762\n","Epoch 74/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.1420 - accuracy: 0.9523 - val_loss: 3.0343 - val_accuracy: 0.4762\n","Epoch 75/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.1207 - accuracy: 0.9543 - val_loss: 3.0881 - val_accuracy: 0.4702\n","Epoch 76/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0880 - accuracy: 0.9722 - val_loss: 3.1134 - val_accuracy: 0.4821\n","Epoch 77/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1293 - accuracy: 0.9682 - val_loss: 3.0306 - val_accuracy: 0.4881\n","Epoch 78/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.0531 - accuracy: 0.9841 - val_loss: 3.5914 - val_accuracy: 0.5000\n","Epoch 79/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0348 - accuracy: 0.9861 - val_loss: 3.7710 - val_accuracy: 0.4702\n","Epoch 80/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1469 - accuracy: 0.9583 - val_loss: 3.3065 - val_accuracy: 0.5119\n","Epoch 81/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.1076 - accuracy: 0.9602 - val_loss: 3.3490 - val_accuracy: 0.4821\n","Epoch 82/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.0667 - accuracy: 0.9722 - val_loss: 3.4184 - val_accuracy: 0.5060\n","Epoch 83/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0671 - accuracy: 0.9722 - val_loss: 3.7851 - val_accuracy: 0.4881\n","Epoch 84/200\n","63/63 [==============================] - 3s 45ms/step - loss: 0.0679 - accuracy: 0.9742 - val_loss: 3.6816 - val_accuracy: 0.4881\n","Epoch 85/200\n","63/63 [==============================] - 4s 62ms/step - loss: 0.1425 - accuracy: 0.9642 - val_loss: 3.0684 - val_accuracy: 0.4464\n","Epoch 86/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1066 - accuracy: 0.9563 - val_loss: 3.4636 - val_accuracy: 0.4702\n","Epoch 87/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.1474 - accuracy: 0.9583 - val_loss: 3.3575 - val_accuracy: 0.4881\n","Epoch 88/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1008 - accuracy: 0.9682 - val_loss: 3.3972 - val_accuracy: 0.4583\n","Epoch 89/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.1250 - accuracy: 0.9682 - val_loss: 3.6905 - val_accuracy: 0.4405\n","Epoch 90/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1267 - accuracy: 0.9622 - val_loss: 3.5030 - val_accuracy: 0.4464\n","Epoch 91/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.0677 - accuracy: 0.9801 - val_loss: 3.7165 - val_accuracy: 0.4583\n","Epoch 92/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.0565 - accuracy: 0.9881 - val_loss: 3.9434 - val_accuracy: 0.4286\n","Epoch 93/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.1304 - accuracy: 0.9622 - val_loss: 3.9323 - val_accuracy: 0.4286\n","Epoch 94/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0784 - accuracy: 0.9801 - val_loss: 3.7314 - val_accuracy: 0.4821\n","Epoch 95/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0728 - accuracy: 0.9742 - val_loss: 3.6692 - val_accuracy: 0.4345\n","Epoch 96/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.0504 - accuracy: 0.9781 - val_loss: 4.0939 - val_accuracy: 0.4345\n","Epoch 97/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1045 - accuracy: 0.9662 - val_loss: 3.5615 - val_accuracy: 0.4226\n","Epoch 98/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1267 - accuracy: 0.9602 - val_loss: 3.8014 - val_accuracy: 0.5000\n","Epoch 99/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1839 - accuracy: 0.9523 - val_loss: 3.4126 - val_accuracy: 0.4524\n","Epoch 100/200\n","63/63 [==============================] - 2s 35ms/step - loss: 0.0763 - accuracy: 0.9722 - val_loss: 3.9014 - val_accuracy: 0.4583\n","Epoch 101/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0964 - accuracy: 0.9722 - val_loss: 3.8443 - val_accuracy: 0.4643\n","Epoch 102/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0961 - accuracy: 0.9602 - val_loss: 3.6442 - val_accuracy: 0.4345\n","Epoch 103/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0654 - accuracy: 0.9682 - val_loss: 3.8415 - val_accuracy: 0.4821\n","Epoch 104/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0930 - accuracy: 0.9761 - val_loss: 3.8149 - val_accuracy: 0.4643\n","Epoch 105/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.1183 - accuracy: 0.9702 - val_loss: 3.4426 - val_accuracy: 0.4643\n","Epoch 106/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0754 - accuracy: 0.9722 - val_loss: 3.6823 - val_accuracy: 0.5238\n","Epoch 107/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0505 - accuracy: 0.9821 - val_loss: 3.8745 - val_accuracy: 0.4940\n","Epoch 108/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.0674 - accuracy: 0.9841 - val_loss: 3.4695 - val_accuracy: 0.4702\n","Epoch 109/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.0542 - accuracy: 0.9761 - val_loss: 3.3189 - val_accuracy: 0.5060\n","Epoch 110/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 3.5529 - val_accuracy: 0.4821\n","Epoch 111/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.0700 - accuracy: 0.9801 - val_loss: 3.4942 - val_accuracy: 0.4702\n","Epoch 112/200\n","63/63 [==============================] - 2s 36ms/step - loss: 0.0759 - accuracy: 0.9781 - val_loss: 3.0189 - val_accuracy: 0.4643\n","Epoch 113/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0773 - accuracy: 0.9801 - val_loss: 3.6017 - val_accuracy: 0.4762\n","Epoch 114/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0615 - accuracy: 0.9801 - val_loss: 3.5561 - val_accuracy: 0.4643\n","Epoch 115/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0744 - accuracy: 0.9742 - val_loss: 3.6933 - val_accuracy: 0.4762\n","Epoch 116/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 3.7515 - val_accuracy: 0.5119\n","Epoch 117/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0794 - accuracy: 0.9642 - val_loss: 3.5522 - val_accuracy: 0.4762\n","Epoch 118/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1132 - accuracy: 0.9662 - val_loss: 3.6210 - val_accuracy: 0.4821\n","Epoch 119/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0732 - accuracy: 0.9742 - val_loss: 3.7628 - val_accuracy: 0.4762\n","Epoch 120/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 3.9350 - val_accuracy: 0.4940\n","Epoch 121/200\n","63/63 [==============================] - 2s 37ms/step - loss: 0.0955 - accuracy: 0.9761 - val_loss: 3.6587 - val_accuracy: 0.4821\n","Epoch 122/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0587 - accuracy: 0.9841 - val_loss: 3.6808 - val_accuracy: 0.4821\n","Epoch 123/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0347 - accuracy: 0.9841 - val_loss: 4.2769 - val_accuracy: 0.4583\n","Epoch 124/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 4.5182 - val_accuracy: 0.4881\n","Epoch 125/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0647 - accuracy: 0.9821 - val_loss: 4.2345 - val_accuracy: 0.4762\n","Epoch 126/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0892 - accuracy: 0.9742 - val_loss: 4.4420 - val_accuracy: 0.4583\n","Epoch 127/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0930 - accuracy: 0.9781 - val_loss: 4.3125 - val_accuracy: 0.4702\n","Epoch 128/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.1868 - accuracy: 0.9483 - val_loss: 3.6456 - val_accuracy: 0.4762\n","Epoch 129/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0965 - accuracy: 0.9642 - val_loss: 3.9522 - val_accuracy: 0.5000\n","Epoch 130/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1236 - accuracy: 0.9682 - val_loss: 3.6437 - val_accuracy: 0.4881\n","Epoch 131/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.1222 - accuracy: 0.9602 - val_loss: 3.5427 - val_accuracy: 0.4821\n","Epoch 132/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0414 - accuracy: 0.9841 - val_loss: 3.7867 - val_accuracy: 0.5000\n","Epoch 133/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0789 - accuracy: 0.9781 - val_loss: 3.5782 - val_accuracy: 0.4881\n","Epoch 134/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0550 - accuracy: 0.9781 - val_loss: 4.1750 - val_accuracy: 0.4940\n","Epoch 135/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0686 - accuracy: 0.9801 - val_loss: 3.9611 - val_accuracy: 0.4702\n","Epoch 136/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0974 - accuracy: 0.9841 - val_loss: 3.4209 - val_accuracy: 0.4881\n","Epoch 137/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0348 - accuracy: 0.9861 - val_loss: 3.6650 - val_accuracy: 0.4821\n","Epoch 138/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0603 - accuracy: 0.9841 - val_loss: 3.8689 - val_accuracy: 0.4940\n","Epoch 139/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0235 - accuracy: 0.9901 - val_loss: 4.2011 - val_accuracy: 0.4762\n","Epoch 140/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0676 - accuracy: 0.9781 - val_loss: 4.1058 - val_accuracy: 0.5000\n","Epoch 141/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0607 - accuracy: 0.9821 - val_loss: 4.2365 - val_accuracy: 0.4881\n","Epoch 142/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0842 - accuracy: 0.9801 - val_loss: 4.3319 - val_accuracy: 0.4702\n","Epoch 143/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0565 - accuracy: 0.9742 - val_loss: 4.4832 - val_accuracy: 0.5060\n","Epoch 144/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 4.2638 - val_accuracy: 0.4762\n","Epoch 145/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0762 - accuracy: 0.9841 - val_loss: 3.7698 - val_accuracy: 0.4702\n","Epoch 146/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0849 - accuracy: 0.9801 - val_loss: 3.7443 - val_accuracy: 0.4881\n","Epoch 147/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0590 - accuracy: 0.9841 - val_loss: 3.6548 - val_accuracy: 0.4821\n","Epoch 148/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0560 - accuracy: 0.9821 - val_loss: 3.7991 - val_accuracy: 0.5119\n","Epoch 149/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0564 - accuracy: 0.9781 - val_loss: 4.0356 - val_accuracy: 0.5000\n","Epoch 150/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0906 - accuracy: 0.9821 - val_loss: 3.9144 - val_accuracy: 0.4881\n","Epoch 151/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.1285 - accuracy: 0.9722 - val_loss: 3.9833 - val_accuracy: 0.4821\n","Epoch 152/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0867 - accuracy: 0.9622 - val_loss: 4.2790 - val_accuracy: 0.5000\n","Epoch 153/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0316 - accuracy: 0.9901 - val_loss: 4.6789 - val_accuracy: 0.5000\n","Epoch 154/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0928 - accuracy: 0.9761 - val_loss: 4.3293 - val_accuracy: 0.5060\n","Epoch 155/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0287 - accuracy: 0.9940 - val_loss: 4.3449 - val_accuracy: 0.5119\n","Epoch 156/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0501 - accuracy: 0.9861 - val_loss: 4.6482 - val_accuracy: 0.4881\n","Epoch 157/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0903 - accuracy: 0.9742 - val_loss: 4.0399 - val_accuracy: 0.5060\n","Epoch 158/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0576 - accuracy: 0.9821 - val_loss: 4.1206 - val_accuracy: 0.4821\n","Epoch 159/200\n","63/63 [==============================] - 3s 46ms/step - loss: 0.0639 - accuracy: 0.9821 - val_loss: 4.2554 - val_accuracy: 0.4821\n","Epoch 160/200\n","63/63 [==============================] - 4s 63ms/step - loss: 0.0652 - accuracy: 0.9761 - val_loss: 4.8784 - val_accuracy: 0.4702\n","Epoch 161/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0524 - accuracy: 0.9861 - val_loss: 4.6068 - val_accuracy: 0.4821\n","Epoch 162/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0763 - accuracy: 0.9682 - val_loss: 4.4863 - val_accuracy: 0.4881\n","Epoch 163/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0714 - accuracy: 0.9742 - val_loss: 5.3171 - val_accuracy: 0.4702\n","Epoch 164/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0941 - accuracy: 0.9702 - val_loss: 5.4840 - val_accuracy: 0.4643\n","Epoch 165/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.1031 - accuracy: 0.9682 - val_loss: 4.8870 - val_accuracy: 0.4940\n","Epoch 166/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.1290 - accuracy: 0.9622 - val_loss: 4.4147 - val_accuracy: 0.5000\n","Epoch 167/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0665 - accuracy: 0.9801 - val_loss: 4.2606 - val_accuracy: 0.5060\n","Epoch 168/200\n","63/63 [==============================] - 2s 38ms/step - loss: 0.0435 - accuracy: 0.9901 - val_loss: 4.7174 - val_accuracy: 0.4940\n","Epoch 169/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0566 - accuracy: 0.9821 - val_loss: 5.0829 - val_accuracy: 0.4643\n","Epoch 170/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.1353 - accuracy: 0.9702 - val_loss: 4.2529 - val_accuracy: 0.4881\n","Epoch 171/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.2390 - accuracy: 0.9463 - val_loss: 3.8738 - val_accuracy: 0.4702\n","Epoch 172/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0697 - accuracy: 0.9761 - val_loss: 4.1152 - val_accuracy: 0.4524\n","Epoch 173/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.1089 - accuracy: 0.9682 - val_loss: 4.2653 - val_accuracy: 0.4643\n","Epoch 174/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0616 - accuracy: 0.9861 - val_loss: 4.7839 - val_accuracy: 0.4762\n","Epoch 175/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0553 - accuracy: 0.9841 - val_loss: 4.7073 - val_accuracy: 0.4881\n","Epoch 176/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0245 - accuracy: 0.9901 - val_loss: 4.8168 - val_accuracy: 0.4762\n","Epoch 177/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0332 - accuracy: 0.9920 - val_loss: 4.8597 - val_accuracy: 0.4643\n","Epoch 178/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0867 - accuracy: 0.9742 - val_loss: 4.2718 - val_accuracy: 0.5238\n","Epoch 179/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0445 - accuracy: 0.9742 - val_loss: 4.4858 - val_accuracy: 0.5298\n","Epoch 180/200\n","63/63 [==============================] - 3s 40ms/step - loss: 0.0256 - accuracy: 0.9881 - val_loss: 4.9439 - val_accuracy: 0.4940\n","Epoch 181/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0573 - accuracy: 0.9781 - val_loss: 4.5776 - val_accuracy: 0.5060\n","Epoch 182/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0208 - accuracy: 0.9881 - val_loss: 4.7154 - val_accuracy: 0.5238\n","Epoch 183/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0765 - accuracy: 0.9761 - val_loss: 4.8935 - val_accuracy: 0.4881\n","Epoch 184/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0893 - accuracy: 0.9722 - val_loss: 4.9086 - val_accuracy: 0.4940\n","Epoch 185/200\n","63/63 [==============================] - 3s 40ms/step - loss: 0.0543 - accuracy: 0.9781 - val_loss: 4.5455 - val_accuracy: 0.4940\n","Epoch 186/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0460 - accuracy: 0.9881 - val_loss: 4.5394 - val_accuracy: 0.5119\n","Epoch 187/200\n","63/63 [==============================] - 2s 40ms/step - loss: 0.0730 - accuracy: 0.9821 - val_loss: 4.3562 - val_accuracy: 0.5060\n","Epoch 188/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0631 - accuracy: 0.9821 - val_loss: 4.2459 - val_accuracy: 0.5000\n","Epoch 189/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0502 - accuracy: 0.9781 - val_loss: 4.7405 - val_accuracy: 0.5119\n","Epoch 190/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0575 - accuracy: 0.9781 - val_loss: 4.9365 - val_accuracy: 0.4881\n","Epoch 191/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.1249 - accuracy: 0.9861 - val_loss: 4.7063 - val_accuracy: 0.4881\n","Epoch 192/200\n","63/63 [==============================] - 3s 40ms/step - loss: 0.0675 - accuracy: 0.9841 - val_loss: 4.4714 - val_accuracy: 0.4940\n","Epoch 193/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0743 - accuracy: 0.9761 - val_loss: 4.5528 - val_accuracy: 0.5357\n","Epoch 194/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 4.3597 - val_accuracy: 0.4464\n","Epoch 195/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0537 - accuracy: 0.9742 - val_loss: 4.5549 - val_accuracy: 0.4940\n","Epoch 196/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0499 - accuracy: 0.9861 - val_loss: 5.3408 - val_accuracy: 0.5119\n","Epoch 197/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0570 - accuracy: 0.9821 - val_loss: 5.7124 - val_accuracy: 0.5060\n","Epoch 198/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0369 - accuracy: 0.9781 - val_loss: 5.6274 - val_accuracy: 0.4762\n","Epoch 199/200\n","63/63 [==============================] - 2s 39ms/step - loss: 0.0455 - accuracy: 0.9781 - val_loss: 5.7898 - val_accuracy: 0.5179\n","Epoch 200/200\n","63/63 [==============================] - 3s 40ms/step - loss: 0.0621 - accuracy: 0.9841 - val_loss: 5.8460 - val_accuracy: 0.4940\n"]}]},{"cell_type":"code","source":["# demonstration of calculating metrics for a neural network model using sklearn\n","from sklearn.datasets import make_circles\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n"],"metadata":{"id":"x40eSRtiljvE","executionInfo":{"status":"ok","timestamp":1663138821520,"user_tz":-360,"elapsed":9,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["yhat_probs = model.predict(x_test, verbose=0)\n","yhat_probs"],"metadata":{"id":"kWIiGXxxlkuU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663138821521,"user_tz":-360,"elapsed":8,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"0d3f643a-8a92-49a9-b99a-f7acd1b71533"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.42155027e-12, 9.49854851e-01, 5.01384661e-02, 6.72440410e-06],\n","       [7.08313882e-02, 1.03330931e-04, 5.17053631e-05, 9.29013550e-01],\n","       [9.99997973e-01, 2.04744288e-06, 6.96336544e-25, 1.83006838e-14],\n","       [3.27004107e-27, 1.70588912e-03, 9.92806554e-01, 5.48744854e-03],\n","       [9.98589575e-01, 1.41036790e-03, 7.29901589e-15, 4.68269796e-08],\n","       [2.40593363e-05, 9.88000333e-01, 3.08340020e-08, 1.19756283e-02],\n","       [4.32841212e-08, 9.93619978e-01, 6.37015654e-03, 9.81711946e-06],\n","       [2.25476593e-29, 9.99656916e-01, 3.42987216e-04, 7.85748213e-08],\n","       [2.96352525e-19, 4.12145168e-01, 5.87854862e-01, 3.04478789e-08],\n","       [3.50582174e-26, 2.00560025e-04, 9.99799430e-01, 2.99388470e-09],\n","       [6.68311850e-06, 9.99979138e-01, 2.52773386e-10, 1.42330155e-05],\n","       [1.00000000e+00, 2.34020403e-09, 5.37798650e-26, 3.98004763e-12],\n","       [5.17536307e-07, 9.47214246e-01, 4.76231603e-14, 5.27851842e-02],\n","       [9.99407649e-01, 1.25312710e-07, 4.56027056e-12, 5.92203636e-04],\n","       [7.70940034e-19, 7.03440368e-01, 2.96559513e-01, 1.34388813e-07],\n","       [7.85361198e-09, 3.49293262e-01, 8.73154349e-05, 6.50619447e-01],\n","       [3.18978182e-17, 9.95747507e-01, 1.14992019e-06, 4.25132457e-03],\n","       [9.83712137e-01, 1.62879098e-02, 2.85226831e-16, 9.38645620e-11],\n","       [1.63828517e-07, 9.91994023e-01, 4.16457729e-10, 8.00580624e-03],\n","       [4.97209445e-20, 1.00000000e+00, 1.92323066e-16, 2.53977826e-20],\n","       [3.31127525e-09, 9.99999881e-01, 1.68867643e-07, 1.36963241e-08],\n","       [1.31529433e-07, 3.83427949e-04, 9.99455512e-01, 1.60981741e-04],\n","       [2.37338127e-09, 9.99976516e-01, 2.34853997e-05, 3.32957620e-13],\n","       [3.37965105e-07, 9.74232554e-01, 2.57433597e-02, 2.37189106e-05],\n","       [7.16810906e-03, 5.29510377e-04, 3.44440615e-10, 9.92302418e-01],\n","       [9.99562681e-01, 1.27421970e-07, 1.10161389e-15, 4.37236420e-04],\n","       [1.04933348e-03, 9.97151196e-01, 1.79948332e-03, 5.30519007e-09],\n","       [4.16265398e-01, 2.27053534e-14, 3.94776307e-13, 5.83734572e-01],\n","       [8.05114794e-11, 3.88852119e-01, 5.86492035e-07, 6.11147285e-01],\n","       [1.27207161e-21, 1.37037583e-04, 9.99786079e-01, 7.68881218e-05],\n","       [7.43180628e-19, 4.10515117e-03, 1.17156851e-04, 9.95777726e-01],\n","       [9.12559869e-07, 1.48911099e-07, 1.32055515e-30, 9.99998927e-01],\n","       [9.99381781e-01, 1.73595705e-04, 4.03140293e-04, 4.14818605e-05],\n","       [8.08521688e-01, 4.97218934e-06, 2.42525360e-08, 1.91473275e-01],\n","       [1.14878602e-01, 1.38144344e-06, 9.36181564e-03, 8.75758171e-01],\n","       [7.20104948e-02, 8.62300456e-01, 5.88658462e-12, 6.56890348e-02],\n","       [4.04064194e-04, 1.82862489e-10, 1.51667537e-05, 9.99580801e-01],\n","       [1.00000000e+00, 4.89046607e-12, 5.98825305e-28, 5.27646726e-09],\n","       [5.60619502e-11, 4.64874238e-01, 4.57887053e-01, 7.72387534e-02],\n","       [1.33512266e-12, 9.16839063e-01, 8.31384212e-02, 2.25351014e-05],\n","       [3.64436310e-05, 7.57162785e-03, 4.62451553e-08, 9.92391884e-01],\n","       [1.00000000e+00, 1.61889391e-22, 0.00000000e+00, 8.07839327e-27],\n","       [4.01845366e-22, 9.96676326e-01, 3.32371052e-03, 2.83282322e-08],\n","       [1.25958820e-06, 9.99939561e-01, 5.91638236e-05, 5.07308813e-11],\n","       [2.25370796e-24, 1.80473015e-01, 8.19518626e-01, 8.45052000e-06],\n","       [1.00000000e+00, 3.03764461e-18, 2.75458919e-21, 3.98045863e-08],\n","       [6.11895211e-02, 9.32644010e-01, 6.48427922e-10, 6.16645813e-03],\n","       [1.19854984e-30, 9.99998212e-01, 1.73343176e-06, 4.10472007e-16],\n","       [9.02021348e-01, 7.55140791e-03, 8.88064727e-02, 1.62089290e-03],\n","       [1.78885679e-19, 9.99925256e-01, 5.81474751e-06, 6.89085937e-05],\n","       [8.66918824e-15, 4.57160324e-01, 5.42828679e-01, 1.09924995e-05],\n","       [4.04375233e-28, 9.99882698e-01, 1.17239309e-04, 1.63850617e-11],\n","       [3.86884302e-08, 1.42888675e-05, 9.99985576e-01, 1.48608905e-07],\n","       [2.16968485e-15, 1.00000000e+00, 8.79308903e-10, 5.27607417e-13],\n","       [1.90762935e-21, 8.85251090e-02, 9.11471128e-01, 3.68150813e-06],\n","       [1.05412363e-08, 9.99584734e-01, 3.02178494e-04, 1.13078364e-04],\n","       [9.99991775e-01, 1.35268966e-11, 8.24507788e-06, 9.20462095e-10],\n","       [1.00000000e+00, 2.78861823e-09, 8.73443003e-26, 5.75738892e-12],\n","       [6.56422199e-05, 3.91733265e-05, 8.39030487e-04, 9.99056160e-01],\n","       [3.27691601e-30, 9.64393765e-02, 9.03560638e-01, 1.84121718e-09],\n","       [3.55440043e-02, 1.13841241e-04, 2.22108056e-07, 9.64341938e-01],\n","       [3.05922212e-14, 4.89787322e-10, 1.00000000e+00, 3.11746474e-15],\n","       [1.00000000e+00, 7.08821853e-17, 5.74441698e-18, 4.66659480e-12],\n","       [1.00000000e+00, 1.11161713e-15, 5.12494926e-38, 2.80839631e-19],\n","       [3.92268197e-11, 9.99999881e-01, 3.64181206e-13, 1.05204670e-07],\n","       [2.23189578e-10, 1.20398470e-26, 9.02530908e-27, 1.00000000e+00],\n","       [9.99685049e-01, 3.60800112e-10, 2.02719365e-13, 3.14921577e-04],\n","       [6.30669918e-24, 9.97777879e-01, 2.21211882e-03, 1.00117149e-05],\n","       [9.96634662e-01, 1.13026845e-05, 8.26772470e-11, 3.35409935e-03],\n","       [2.92114091e-05, 1.50647298e-01, 4.82335031e-01, 3.66988480e-01],\n","       [3.42127382e-14, 1.87402664e-04, 9.99576271e-01, 2.36346066e-04],\n","       [9.99928713e-01, 7.41311723e-08, 1.91075446e-06, 6.92054527e-05],\n","       [1.86751307e-20, 9.99999285e-01, 2.82385262e-08, 6.85412033e-07],\n","       [9.99970198e-01, 8.78717344e-07, 7.70480820e-14, 2.89239615e-05],\n","       [3.24541211e-18, 3.56574118e-01, 6.43390059e-01, 3.58834805e-05],\n","       [5.49794606e-07, 9.99997139e-01, 5.31360200e-15, 2.21338087e-06],\n","       [9.86733377e-01, 1.31334476e-02, 5.54654962e-16, 1.33210575e-04],\n","       [8.05934633e-06, 1.78621121e-04, 9.58593428e-01, 4.12198417e-02],\n","       [9.99833107e-01, 1.66296624e-04, 5.75900276e-14, 6.10982227e-07],\n","       [3.58374596e-01, 4.52411383e-01, 2.52901297e-02, 1.63923964e-01],\n","       [4.88937450e-12, 1.00000000e+00, 4.51899048e-24, 3.62912310e-13],\n","       [4.91165719e-10, 9.95688021e-01, 1.84455863e-03, 2.46740715e-03],\n","       [1.00000000e+00, 1.30607773e-08, 6.51800568e-31, 6.35826353e-13],\n","       [9.58062351e-01, 4.16022018e-02, 3.64902668e-08, 3.35380086e-04],\n","       [9.99799311e-01, 2.00695475e-04, 4.47625936e-09, 2.03753707e-08],\n","       [9.99999046e-01, 9.43644693e-07, 1.95001189e-20, 1.31819196e-08],\n","       [5.91814207e-08, 9.70974386e-01, 2.88263634e-02, 1.99053989e-04],\n","       [8.89299759e-17, 9.60543633e-01, 7.42350705e-04, 3.87140252e-02],\n","       [9.99932408e-01, 3.86389892e-10, 2.00041887e-15, 6.76317140e-05],\n","       [1.02563534e-24, 9.77232516e-01, 2.27674711e-02, 3.06913934e-12],\n","       [9.88883464e-09, 9.98668075e-01, 4.68945155e-14, 1.33188872e-03],\n","       [2.07111333e-02, 1.46206921e-05, 2.05497839e-04, 9.79068756e-01],\n","       [1.49599933e-11, 8.85843158e-01, 1.14156753e-01, 9.58347712e-08],\n","       [2.47743666e-01, 6.40459597e-01, 7.93849264e-10, 1.11796655e-01],\n","       [1.00000000e+00, 3.55767564e-12, 1.16874982e-20, 3.74634794e-08],\n","       [1.86616016e-04, 3.81160408e-01, 6.18041039e-01, 6.11938245e-04],\n","       [2.96695710e-16, 9.98937786e-01, 3.40975355e-08, 1.06221077e-03],\n","       [8.77184094e-19, 1.56700283e-01, 8.43265712e-01, 3.40371407e-05],\n","       [7.72071643e-12, 9.99979496e-01, 2.03934414e-05, 1.54162549e-07],\n","       [1.44502440e-06, 2.21135961e-05, 8.78999710e-01, 1.20976694e-01],\n","       [1.28205805e-11, 1.00000000e+00, 2.26688392e-13, 2.12507928e-11],\n","       [3.14516131e-25, 1.47565338e-19, 1.00000000e+00, 3.08078718e-26],\n","       [1.15612854e-22, 9.99999881e-01, 4.49454057e-10, 7.86875773e-08],\n","       [3.73450280e-06, 9.89762008e-01, 3.91389942e-03, 6.32031076e-03],\n","       [7.67055567e-17, 3.95454736e-05, 9.99960303e-01, 8.74424799e-08],\n","       [1.00000000e+00, 3.93649170e-13, 6.11126524e-32, 2.25279040e-12],\n","       [9.99374211e-01, 5.47373658e-09, 5.17361603e-18, 6.25818677e-04],\n","       [1.00000000e+00, 1.23904836e-12, 4.47522566e-25, 9.32778770e-15],\n","       [9.99999881e-01, 2.91191038e-15, 3.95753942e-21, 7.80938478e-08],\n","       [9.99201715e-01, 7.98197638e-04, 1.69421526e-07, 3.20133763e-12],\n","       [9.95640397e-01, 4.35880339e-03, 4.56699396e-14, 7.82270604e-07],\n","       [1.25733649e-07, 9.99998927e-01, 5.43439000e-07, 4.12240695e-07],\n","       [4.62910673e-03, 1.28501588e-02, 9.82520759e-01, 8.06279609e-12],\n","       [9.97995496e-01, 7.90988075e-09, 8.89214460e-17, 2.00455426e-03],\n","       [1.97492725e-13, 1.00000000e+00, 4.62438334e-12, 1.28535647e-18],\n","       [9.99997139e-01, 1.32384926e-07, 3.39228781e-16, 2.77823301e-06],\n","       [1.08532438e-21, 1.88799305e-08, 6.24930067e-07, 9.99999404e-01],\n","       [2.18672561e-03, 1.14877825e-03, 6.13800228e-01, 3.82864207e-01],\n","       [6.12466156e-01, 3.76081407e-01, 1.22748367e-09, 1.14523843e-02],\n","       [8.60434840e-04, 2.45065686e-11, 3.41796339e-12, 9.99139547e-01],\n","       [2.09438458e-08, 9.72273767e-01, 8.31184508e-08, 2.77261604e-02],\n","       [5.56781251e-14, 2.47758459e-02, 9.27366734e-01, 4.78573814e-02],\n","       [1.00000000e+00, 1.09049033e-16, 4.51016005e-37, 3.93091361e-26],\n","       [1.39393885e-09, 1.00000000e+00, 6.41527886e-19, 1.54768898e-13],\n","       [6.40760129e-03, 1.39256928e-09, 9.67488945e-01, 2.61034500e-02],\n","       [8.24274361e-01, 1.75393384e-03, 5.98491388e-05, 1.73911840e-01],\n","       [1.32934536e-22, 4.73873643e-03, 9.95261252e-01, 4.79633897e-08],\n","       [1.93983931e-21, 9.99049723e-01, 9.50264977e-04, 1.12395414e-11],\n","       [3.79059129e-05, 5.93148232e-01, 4.06684339e-01, 1.29550768e-04],\n","       [7.15748349e-09, 9.98475730e-01, 1.23537448e-03, 2.88898387e-04],\n","       [9.99877214e-01, 9.31223781e-07, 1.25329299e-18, 1.21763333e-04],\n","       [3.26898370e-17, 6.65375054e-01, 3.34624261e-01, 7.06486048e-07],\n","       [5.52365653e-18, 1.00000000e+00, 1.23704224e-14, 8.84010753e-10],\n","       [1.78357296e-12, 2.89082869e-10, 1.00000000e+00, 2.94860122e-12],\n","       [6.42095087e-14, 9.45943475e-01, 5.40554151e-02, 1.12096825e-06],\n","       [1.00000000e+00, 2.59311075e-22, 5.31905913e-35, 1.41923166e-17],\n","       [1.74037029e-09, 6.19974770e-02, 9.14637804e-01, 2.33648028e-02],\n","       [1.00000000e+00, 1.19327264e-13, 1.16017170e-21, 8.08878209e-09],\n","       [1.15320690e-04, 9.99884725e-01, 9.08111000e-12, 7.42712315e-13],\n","       [1.27876909e-08, 9.99947548e-01, 1.65640224e-10, 5.24187126e-05],\n","       [2.29684312e-22, 1.00000000e+00, 6.67561371e-21, 5.57355038e-16],\n","       [7.76382076e-05, 6.45104766e-01, 3.53291780e-01, 1.52585714e-03],\n","       [3.95148546e-16, 5.90134661e-08, 1.00000000e+00, 3.93900028e-13],\n","       [2.75044662e-25, 1.00000000e+00, 7.45253789e-11, 1.26060282e-08],\n","       [9.99999881e-01, 2.35801876e-16, 1.66953451e-18, 7.92388093e-08],\n","       [1.00000000e+00, 2.57963744e-19, 1.18611835e-35, 7.32888971e-17],\n","       [3.92268402e-18, 4.02272008e-02, 9.59735572e-01, 3.72025679e-05],\n","       [9.79658723e-01, 1.25417113e-02, 9.25783972e-14, 7.79954437e-03],\n","       [6.51526742e-19, 6.34871947e-04, 9.99360263e-01, 4.88456089e-06],\n","       [2.05949831e-07, 2.77170415e-07, 1.64031712e-19, 9.99999523e-01],\n","       [1.20019984e-11, 1.82664880e-04, 1.03184288e-10, 9.99817312e-01],\n","       [1.71844340e-15, 7.28199724e-03, 9.92712796e-01, 5.20830235e-06],\n","       [9.94927287e-01, 5.07275434e-03, 5.70013674e-21, 2.62451905e-09],\n","       [9.04738408e-21, 8.74316156e-01, 1.25651240e-01, 3.26556947e-05],\n","       [9.99936461e-01, 1.08457196e-23, 2.20621158e-29, 6.34778044e-05],\n","       [9.97504532e-01, 2.49530515e-03, 2.04949362e-14, 6.43194156e-08],\n","       [6.63277460e-03, 9.39553380e-02, 6.44980013e-01, 2.54431874e-01],\n","       [2.76169026e-32, 9.37620878e-01, 6.23788573e-02, 2.17065320e-07],\n","       [9.99999881e-01, 1.61677605e-08, 2.05543042e-23, 1.04470210e-07],\n","       [2.70722900e-03, 9.97292697e-01, 1.95578095e-14, 2.17349223e-13],\n","       [3.92395138e-36, 9.99991059e-01, 8.93178822e-06, 1.12241882e-09],\n","       [1.00000000e+00, 7.86439056e-12, 1.11981898e-22, 4.25226521e-09],\n","       [7.71094817e-14, 7.32315063e-01, 1.20984776e-11, 2.67684937e-01],\n","       [1.95929974e-11, 1.11630798e-04, 9.99859452e-01, 2.88428364e-05],\n","       [4.26167617e-07, 4.66837434e-07, 9.99999166e-01, 2.36626256e-08],\n","       [9.99489069e-01, 5.10870072e-04, 2.65827455e-21, 2.21720016e-12],\n","       [9.99999285e-01, 4.31203476e-11, 6.35349673e-16, 7.72027818e-07],\n","       [1.10035350e-08, 3.02967161e-01, 6.97032809e-01, 8.31510860e-10]],\n","      dtype=float32)"]},"metadata":{},"execution_count":47}]}]}