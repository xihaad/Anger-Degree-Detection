{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBzRgHMoJlLtbrPQO8mwnU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQ9MQaj_omTa","executionInfo":{"status":"ok","timestamp":1663135393792,"user_tz":-360,"elapsed":19630,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"a1515bea-1eed-4c6a-e88f-14d6278bc47e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from imblearn.over_sampling import SMOTE\n","import os\n","import sys\n","\n","# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n","import librosa\n","import librosa.display\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","# to play the audio files\n","from IPython.display import Audio\n","\n","import keras\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n","from keras.utils import np_utils\n","from tensorflow.keras.utils import to_categorical\n","from keras.callbacks import ModelCheckpoint"],"metadata":{"id":"3K9J7x_Wp_3q","executionInfo":{"status":"ok","timestamp":1663135399355,"user_tz":-360,"elapsed":5569,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, recall_score, precision_score\n","import math\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","# Importing the dataset\n","Features = pd.read_csv('/content/drive/MyDrive/DataMining/Datasets/Selected_Features.csv')\n","X = Features.iloc[: ,:-1].values\n","Y = Features['class'].values\n"],"metadata":{"id":"G0HwGeBnos6S","executionInfo":{"status":"ok","timestamp":1663135400500,"user_tz":-360,"elapsed":1148,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# # As this is a multiclass classification problem onehotencoding our Y.\n","# encoder = OneHotEncoder()\n","# Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"],"metadata":{"id":"Kdsb7fnootj4","executionInfo":{"status":"ok","timestamp":1663135400500,"user_tz":-360,"elapsed":11,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# splitting data\n","smote_on_1 = 212\n","smote = SMOTE(sampling_strategy={'Minimal': smote_on_1,'Moderate': smote_on_1, 'Extreme': smote_on_1})\n","X, Y = smote.fit_resample(X, Y)\n","encoder = OneHotEncoder()\n","Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xiO6IEvXpVqP","executionInfo":{"status":"ok","timestamp":1663135400501,"user_tz":-360,"elapsed":11,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"9fd2dea0-a288-4161-91b0-a1bd9cb91a94"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((636, 26), (636, 4), (212, 26), (212, 4))"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# scaling our data with sklearn's Standard scaler\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QZ8JP-6vpgjE","executionInfo":{"status":"ok","timestamp":1663135400501,"user_tz":-360,"elapsed":9,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"43a74269-77c5-4038-abc6-4dc36f4154c2"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((636, 26), (636, 4), (212, 26), (212, 4))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# making our data compatible to model.\n","x_train = np.expand_dims(x_train, axis=2)\n","x_test = np.expand_dims(x_test, axis=2)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bw2ig4ASwoDj","executionInfo":{"status":"ok","timestamp":1663135400502,"user_tz":-360,"elapsed":8,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"e8304cec-757d-49d7-fcc7-12d3fba557e8"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((636, 26, 1), (636, 4), (212, 26, 1), (212, 4))"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# # # making our data compatible to model.\n","# # x_train = np.expand_dims(x_train, axis=2)\n","# # x_test = np.expand_dims(x_test, axis=2)\n","# y_train = np.expand_dims(y_train, axis=1)\n","# x_train.shape, y_train.shape, x_test.shape, y_test.shape"],"metadata":{"id":"8xI2ttebpvH-","executionInfo":{"status":"ok","timestamp":1663135400503,"user_tz":-360,"elapsed":7,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n"],"metadata":{"id":"OSd_cSRyuQEV","executionInfo":{"status":"ok","timestamp":1663135400503,"user_tz":-360,"elapsed":7,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model=Sequential()\n","model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n","# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n","# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n","# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n","# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n","model.add(Dropout(0.3))\n","\n","model.add(Flatten())\n","model.add(Dense(units=32, activation='relu'))\n","# model.add(Dropout(0.3))\n","\n","model.add(Dense(units=4, activation='softmax'))\n","model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeZgfNWNpyPt","executionInfo":{"status":"ok","timestamp":1663135401122,"user_tz":-360,"elapsed":626,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"c24d9a4f-2403-4268-f304-8b4fb6c33a09"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d (Conv1D)             (None, 26, 256)           1536      \n","                                                                 \n"," dropout (Dropout)           (None, 26, 256)           0         \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 26, 256)           327936    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 26, 256)           0         \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 26, 128)           163968    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 26, 128)           0         \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 26, 64)            41024     \n","                                                                 \n"," dropout_3 (Dropout)         (None, 26, 64)            0         \n","                                                                 \n"," flatten (Flatten)           (None, 1664)              0         \n","                                                                 \n"," dense (Dense)               (None, 32)                53280     \n","                                                                 \n"," dense_1 (Dense)             (None, 4)                 132       \n","                                                                 \n","=================================================================\n","Total params: 587,876\n","Trainable params: 587,876\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n","# history=model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[rlrp])\n","history=model.fit(x_train, y_train, batch_size=8, epochs=200, validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0eggGrvrvhh","executionInfo":{"status":"ok","timestamp":1663136024397,"user_tz":-360,"elapsed":623280,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"5e0842b5-2bed-43eb-ff24-bff8ef5abff7"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","80/80 [==============================] - 5s 41ms/step - loss: 1.1901 - accuracy: 0.4560 - val_loss: 1.0901 - val_accuracy: 0.4906\n","Epoch 2/200\n","80/80 [==============================] - 3s 35ms/step - loss: 1.1012 - accuracy: 0.5031 - val_loss: 1.1205 - val_accuracy: 0.5000\n","Epoch 3/200\n","80/80 [==============================] - 3s 36ms/step - loss: 1.0659 - accuracy: 0.5330 - val_loss: 1.0409 - val_accuracy: 0.5094\n","Epoch 4/200\n","80/80 [==============================] - 3s 43ms/step - loss: 1.0297 - accuracy: 0.5000 - val_loss: 1.0177 - val_accuracy: 0.5236\n","Epoch 5/200\n","80/80 [==============================] - 3s 38ms/step - loss: 1.0028 - accuracy: 0.5503 - val_loss: 0.9998 - val_accuracy: 0.5236\n","Epoch 6/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.9827 - accuracy: 0.5613 - val_loss: 0.9762 - val_accuracy: 0.5708\n","Epoch 7/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.9733 - accuracy: 0.5770 - val_loss: 0.9782 - val_accuracy: 0.5519\n","Epoch 8/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.9443 - accuracy: 0.5708 - val_loss: 0.9970 - val_accuracy: 0.5425\n","Epoch 9/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.9091 - accuracy: 0.6038 - val_loss: 0.9798 - val_accuracy: 0.5283\n","Epoch 10/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.8873 - accuracy: 0.6211 - val_loss: 0.9352 - val_accuracy: 0.5755\n","Epoch 11/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.8626 - accuracy: 0.6132 - val_loss: 1.0103 - val_accuracy: 0.5519\n","Epoch 12/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.8127 - accuracy: 0.6698 - val_loss: 0.9622 - val_accuracy: 0.5660\n","Epoch 13/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.7874 - accuracy: 0.6714 - val_loss: 0.9148 - val_accuracy: 0.5896\n","Epoch 14/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.7492 - accuracy: 0.6887 - val_loss: 0.9620 - val_accuracy: 0.6038\n","Epoch 15/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.7356 - accuracy: 0.6572 - val_loss: 0.9495 - val_accuracy: 0.5755\n","Epoch 16/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.7171 - accuracy: 0.7013 - val_loss: 1.0587 - val_accuracy: 0.5519\n","Epoch 17/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.6729 - accuracy: 0.7123 - val_loss: 1.0426 - val_accuracy: 0.5755\n","Epoch 18/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.6129 - accuracy: 0.7626 - val_loss: 1.0504 - val_accuracy: 0.5566\n","Epoch 19/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.6232 - accuracy: 0.7563 - val_loss: 1.0844 - val_accuracy: 0.5849\n","Epoch 20/200\n","80/80 [==============================] - 4s 51ms/step - loss: 0.5510 - accuracy: 0.7579 - val_loss: 1.1873 - val_accuracy: 0.5613\n","Epoch 21/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.5344 - accuracy: 0.7862 - val_loss: 1.1284 - val_accuracy: 0.5802\n","Epoch 22/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.5275 - accuracy: 0.7814 - val_loss: 1.2078 - val_accuracy: 0.6038\n","Epoch 23/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.4525 - accuracy: 0.8302 - val_loss: 1.3401 - val_accuracy: 0.5755\n","Epoch 24/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.4232 - accuracy: 0.8255 - val_loss: 1.3533 - val_accuracy: 0.5755\n","Epoch 25/200\n","80/80 [==============================] - 5s 66ms/step - loss: 0.3850 - accuracy: 0.8443 - val_loss: 1.5360 - val_accuracy: 0.6038\n","Epoch 26/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.4523 - accuracy: 0.8176 - val_loss: 1.4281 - val_accuracy: 0.5849\n","Epoch 27/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.4558 - accuracy: 0.8208 - val_loss: 1.3170 - val_accuracy: 0.6462\n","Epoch 28/200\n","80/80 [==============================] - 4s 45ms/step - loss: 0.3927 - accuracy: 0.8396 - val_loss: 1.4779 - val_accuracy: 0.5802\n","Epoch 29/200\n","80/80 [==============================] - 4s 45ms/step - loss: 0.3318 - accuracy: 0.8758 - val_loss: 1.5977 - val_accuracy: 0.6085\n","Epoch 30/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.3184 - accuracy: 0.8805 - val_loss: 1.4095 - val_accuracy: 0.6226\n","Epoch 31/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.3218 - accuracy: 0.8774 - val_loss: 1.5526 - val_accuracy: 0.6226\n","Epoch 32/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.3310 - accuracy: 0.8852 - val_loss: 1.5624 - val_accuracy: 0.5802\n","Epoch 33/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.2760 - accuracy: 0.9119 - val_loss: 1.8600 - val_accuracy: 0.5849\n","Epoch 34/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.3059 - accuracy: 0.8899 - val_loss: 1.5161 - val_accuracy: 0.5991\n","Epoch 35/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.2746 - accuracy: 0.9041 - val_loss: 1.7015 - val_accuracy: 0.5896\n","Epoch 36/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.2259 - accuracy: 0.9135 - val_loss: 1.7765 - val_accuracy: 0.6226\n","Epoch 37/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.2488 - accuracy: 0.9088 - val_loss: 2.0873 - val_accuracy: 0.5991\n","Epoch 38/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.2352 - accuracy: 0.9151 - val_loss: 1.8699 - val_accuracy: 0.6226\n","Epoch 39/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.2127 - accuracy: 0.9261 - val_loss: 1.8791 - val_accuracy: 0.5896\n","Epoch 40/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.2635 - accuracy: 0.9041 - val_loss: 2.1609 - val_accuracy: 0.6038\n","Epoch 41/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.2525 - accuracy: 0.9072 - val_loss: 1.7278 - val_accuracy: 0.6132\n","Epoch 42/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1962 - accuracy: 0.9261 - val_loss: 1.9076 - val_accuracy: 0.6085\n","Epoch 43/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.2176 - accuracy: 0.9167 - val_loss: 1.7799 - val_accuracy: 0.6038\n","Epoch 44/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.2235 - accuracy: 0.9277 - val_loss: 1.7876 - val_accuracy: 0.6085\n","Epoch 45/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1834 - accuracy: 0.9371 - val_loss: 1.9050 - val_accuracy: 0.5991\n","Epoch 46/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.2633 - accuracy: 0.9072 - val_loss: 1.8986 - val_accuracy: 0.6179\n","Epoch 47/200\n","80/80 [==============================] - 3s 35ms/step - loss: 0.1834 - accuracy: 0.9167 - val_loss: 2.0889 - val_accuracy: 0.6038\n","Epoch 48/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1507 - accuracy: 0.9418 - val_loss: 2.0951 - val_accuracy: 0.6132\n","Epoch 49/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1674 - accuracy: 0.9403 - val_loss: 1.7814 - val_accuracy: 0.6274\n","Epoch 50/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1337 - accuracy: 0.9434 - val_loss: 2.1172 - val_accuracy: 0.6509\n","Epoch 51/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.1545 - accuracy: 0.9450 - val_loss: 2.3711 - val_accuracy: 0.6274\n","Epoch 52/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.2203 - accuracy: 0.9261 - val_loss: 2.0175 - val_accuracy: 0.5849\n","Epoch 53/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1436 - accuracy: 0.9450 - val_loss: 2.3849 - val_accuracy: 0.5943\n","Epoch 54/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1850 - accuracy: 0.9403 - val_loss: 2.3416 - val_accuracy: 0.6132\n","Epoch 55/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1467 - accuracy: 0.9450 - val_loss: 2.3479 - val_accuracy: 0.6321\n","Epoch 56/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1790 - accuracy: 0.9340 - val_loss: 2.4328 - val_accuracy: 0.6226\n","Epoch 57/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1266 - accuracy: 0.9528 - val_loss: 2.3444 - val_accuracy: 0.6415\n","Epoch 58/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1137 - accuracy: 0.9544 - val_loss: 2.2430 - val_accuracy: 0.6274\n","Epoch 59/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1347 - accuracy: 0.9450 - val_loss: 2.4199 - val_accuracy: 0.6132\n","Epoch 60/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1731 - accuracy: 0.9450 - val_loss: 2.5989 - val_accuracy: 0.6274\n","Epoch 61/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1579 - accuracy: 0.9560 - val_loss: 2.1807 - val_accuracy: 0.6321\n","Epoch 62/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1356 - accuracy: 0.9528 - val_loss: 2.4309 - val_accuracy: 0.6226\n","Epoch 63/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1030 - accuracy: 0.9638 - val_loss: 2.6418 - val_accuracy: 0.6604\n","Epoch 64/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1135 - accuracy: 0.9623 - val_loss: 2.6913 - val_accuracy: 0.6415\n","Epoch 65/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1877 - accuracy: 0.9403 - val_loss: 2.5215 - val_accuracy: 0.6132\n","Epoch 66/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1237 - accuracy: 0.9560 - val_loss: 2.6996 - val_accuracy: 0.6085\n","Epoch 67/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1368 - accuracy: 0.9638 - val_loss: 2.4843 - val_accuracy: 0.6368\n","Epoch 68/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0995 - accuracy: 0.9638 - val_loss: 2.6889 - val_accuracy: 0.6321\n","Epoch 69/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0913 - accuracy: 0.9780 - val_loss: 3.2738 - val_accuracy: 0.6368\n","Epoch 70/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1145 - accuracy: 0.9607 - val_loss: 2.7083 - val_accuracy: 0.6132\n","Epoch 71/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1364 - accuracy: 0.9528 - val_loss: 2.7646 - val_accuracy: 0.6038\n","Epoch 72/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1271 - accuracy: 0.9591 - val_loss: 2.3100 - val_accuracy: 0.5991\n","Epoch 73/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1236 - accuracy: 0.9544 - val_loss: 2.5668 - val_accuracy: 0.6132\n","Epoch 74/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1185 - accuracy: 0.9686 - val_loss: 2.5483 - val_accuracy: 0.5991\n","Epoch 75/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0976 - accuracy: 0.9701 - val_loss: 2.7196 - val_accuracy: 0.5849\n","Epoch 76/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1053 - accuracy: 0.9654 - val_loss: 2.5838 - val_accuracy: 0.6368\n","Epoch 77/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1209 - accuracy: 0.9560 - val_loss: 3.1302 - val_accuracy: 0.6274\n","Epoch 78/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1930 - accuracy: 0.9387 - val_loss: 3.1928 - val_accuracy: 0.6321\n","Epoch 79/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1386 - accuracy: 0.9560 - val_loss: 2.3715 - val_accuracy: 0.6604\n","Epoch 80/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0825 - accuracy: 0.9717 - val_loss: 2.3956 - val_accuracy: 0.6509\n","Epoch 81/200\n","80/80 [==============================] - 4s 54ms/step - loss: 0.0951 - accuracy: 0.9701 - val_loss: 2.9138 - val_accuracy: 0.6509\n","Epoch 82/200\n","80/80 [==============================] - 3s 43ms/step - loss: 0.1445 - accuracy: 0.9544 - val_loss: 3.2385 - val_accuracy: 0.6038\n","Epoch 83/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1423 - accuracy: 0.9497 - val_loss: 2.6806 - val_accuracy: 0.6509\n","Epoch 84/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1178 - accuracy: 0.9528 - val_loss: 3.1781 - val_accuracy: 0.6274\n","Epoch 85/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1007 - accuracy: 0.9623 - val_loss: 3.1424 - val_accuracy: 0.6415\n","Epoch 86/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1181 - accuracy: 0.9560 - val_loss: 3.0217 - val_accuracy: 0.5896\n","Epoch 87/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0999 - accuracy: 0.9670 - val_loss: 3.0860 - val_accuracy: 0.6038\n","Epoch 88/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1367 - accuracy: 0.9591 - val_loss: 3.0649 - val_accuracy: 0.6698\n","Epoch 89/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1283 - accuracy: 0.9638 - val_loss: 2.9021 - val_accuracy: 0.6368\n","Epoch 90/200\n","80/80 [==============================] - 3s 35ms/step - loss: 0.1111 - accuracy: 0.9623 - val_loss: 2.6574 - val_accuracy: 0.6509\n","Epoch 91/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0730 - accuracy: 0.9748 - val_loss: 2.9411 - val_accuracy: 0.6274\n","Epoch 92/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.1166 - accuracy: 0.9701 - val_loss: 2.9548 - val_accuracy: 0.6179\n","Epoch 93/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1145 - accuracy: 0.9733 - val_loss: 2.5436 - val_accuracy: 0.6792\n","Epoch 94/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0705 - accuracy: 0.9733 - val_loss: 2.7277 - val_accuracy: 0.6557\n","Epoch 95/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1361 - accuracy: 0.9591 - val_loss: 3.2303 - val_accuracy: 0.6415\n","Epoch 96/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1025 - accuracy: 0.9733 - val_loss: 2.7379 - val_accuracy: 0.6462\n","Epoch 97/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1123 - accuracy: 0.9686 - val_loss: 2.9580 - val_accuracy: 0.6321\n","Epoch 98/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0841 - accuracy: 0.9796 - val_loss: 2.8406 - val_accuracy: 0.6509\n","Epoch 99/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0771 - accuracy: 0.9780 - val_loss: 3.1495 - val_accuracy: 0.6179\n","Epoch 100/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0726 - accuracy: 0.9796 - val_loss: 3.2842 - val_accuracy: 0.6509\n","Epoch 101/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0425 - accuracy: 0.9890 - val_loss: 3.5569 - val_accuracy: 0.6321\n","Epoch 102/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0428 - accuracy: 0.9827 - val_loss: 3.3535 - val_accuracy: 0.6462\n","Epoch 103/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.0849 - accuracy: 0.9717 - val_loss: 3.9823 - val_accuracy: 0.6462\n","Epoch 104/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0761 - accuracy: 0.9827 - val_loss: 3.2211 - val_accuracy: 0.6274\n","Epoch 105/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1478 - accuracy: 0.9654 - val_loss: 3.3220 - val_accuracy: 0.6321\n","Epoch 106/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1728 - accuracy: 0.9528 - val_loss: 3.2887 - val_accuracy: 0.6085\n","Epoch 107/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1877 - accuracy: 0.9560 - val_loss: 2.8720 - val_accuracy: 0.5991\n","Epoch 108/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.0950 - accuracy: 0.9654 - val_loss: 2.7876 - val_accuracy: 0.6462\n","Epoch 109/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0444 - accuracy: 0.9827 - val_loss: 3.1149 - val_accuracy: 0.6462\n","Epoch 110/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0579 - accuracy: 0.9780 - val_loss: 3.3703 - val_accuracy: 0.6698\n","Epoch 111/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0713 - accuracy: 0.9780 - val_loss: 3.1612 - val_accuracy: 0.6509\n","Epoch 112/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0569 - accuracy: 0.9796 - val_loss: 3.2784 - val_accuracy: 0.6604\n","Epoch 113/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.0777 - accuracy: 0.9843 - val_loss: 3.1347 - val_accuracy: 0.6792\n","Epoch 114/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0823 - accuracy: 0.9748 - val_loss: 3.5072 - val_accuracy: 0.6509\n","Epoch 115/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1041 - accuracy: 0.9654 - val_loss: 3.1893 - val_accuracy: 0.6792\n","Epoch 116/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0533 - accuracy: 0.9796 - val_loss: 3.4957 - val_accuracy: 0.6557\n","Epoch 117/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1270 - accuracy: 0.9607 - val_loss: 3.3129 - val_accuracy: 0.6274\n","Epoch 118/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0938 - accuracy: 0.9701 - val_loss: 3.7809 - val_accuracy: 0.6085\n","Epoch 119/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1081 - accuracy: 0.9748 - val_loss: 2.9234 - val_accuracy: 0.6415\n","Epoch 120/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.1013 - accuracy: 0.9670 - val_loss: 3.4011 - val_accuracy: 0.6226\n","Epoch 121/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.0404 - accuracy: 0.9858 - val_loss: 3.6276 - val_accuracy: 0.6132\n","Epoch 122/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0973 - accuracy: 0.9748 - val_loss: 3.7086 - val_accuracy: 0.6368\n","Epoch 123/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0985 - accuracy: 0.9670 - val_loss: 3.5075 - val_accuracy: 0.6179\n","Epoch 124/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1770 - accuracy: 0.9528 - val_loss: 3.0347 - val_accuracy: 0.6462\n","Epoch 125/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.0963 - accuracy: 0.9717 - val_loss: 3.3718 - val_accuracy: 0.6368\n","Epoch 126/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.0864 - accuracy: 0.9796 - val_loss: 3.2614 - val_accuracy: 0.6462\n","Epoch 127/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.0814 - accuracy: 0.9701 - val_loss: 3.1996 - val_accuracy: 0.6698\n","Epoch 128/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1353 - accuracy: 0.9733 - val_loss: 3.0372 - val_accuracy: 0.6462\n","Epoch 129/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0538 - accuracy: 0.9780 - val_loss: 2.8207 - val_accuracy: 0.6415\n","Epoch 130/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0672 - accuracy: 0.9827 - val_loss: 3.0359 - val_accuracy: 0.6415\n","Epoch 131/200\n","80/80 [==============================] - 3s 39ms/step - loss: 0.0838 - accuracy: 0.9780 - val_loss: 3.0934 - val_accuracy: 0.6462\n","Epoch 132/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0316 - accuracy: 0.9890 - val_loss: 3.4122 - val_accuracy: 0.6321\n","Epoch 133/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1206 - accuracy: 0.9717 - val_loss: 3.8009 - val_accuracy: 0.6274\n","Epoch 134/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0913 - accuracy: 0.9764 - val_loss: 3.3720 - val_accuracy: 0.6509\n","Epoch 135/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 3.3916 - val_accuracy: 0.6368\n","Epoch 136/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0626 - accuracy: 0.9764 - val_loss: 3.4570 - val_accuracy: 0.6368\n","Epoch 137/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0869 - accuracy: 0.9686 - val_loss: 4.0265 - val_accuracy: 0.6368\n","Epoch 138/200\n","80/80 [==============================] - 4s 46ms/step - loss: 0.1843 - accuracy: 0.9670 - val_loss: 3.3965 - val_accuracy: 0.6745\n","Epoch 139/200\n","80/80 [==============================] - 4s 52ms/step - loss: 0.0611 - accuracy: 0.9858 - val_loss: 3.5260 - val_accuracy: 0.6415\n","Epoch 140/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0556 - accuracy: 0.9780 - val_loss: 3.1807 - val_accuracy: 0.6745\n","Epoch 141/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0575 - accuracy: 0.9827 - val_loss: 3.1518 - val_accuracy: 0.6604\n","Epoch 142/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 3.6765 - val_accuracy: 0.6368\n","Epoch 143/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0628 - accuracy: 0.9811 - val_loss: 3.4214 - val_accuracy: 0.6462\n","Epoch 144/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0497 - accuracy: 0.9843 - val_loss: 3.7881 - val_accuracy: 0.6651\n","Epoch 145/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1077 - accuracy: 0.9717 - val_loss: 3.5997 - val_accuracy: 0.6321\n","Epoch 146/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0503 - accuracy: 0.9858 - val_loss: 3.9042 - val_accuracy: 0.6415\n","Epoch 147/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0754 - accuracy: 0.9796 - val_loss: 3.9996 - val_accuracy: 0.6085\n","Epoch 148/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0781 - accuracy: 0.9717 - val_loss: 3.7413 - val_accuracy: 0.6179\n","Epoch 149/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1123 - accuracy: 0.9733 - val_loss: 3.8733 - val_accuracy: 0.6132\n","Epoch 150/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0612 - accuracy: 0.9827 - val_loss: 3.8036 - val_accuracy: 0.6368\n","Epoch 151/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0755 - accuracy: 0.9780 - val_loss: 3.5364 - val_accuracy: 0.6226\n","Epoch 152/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1022 - accuracy: 0.9796 - val_loss: 3.6268 - val_accuracy: 0.6462\n","Epoch 153/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0534 - accuracy: 0.9858 - val_loss: 4.0427 - val_accuracy: 0.6274\n","Epoch 154/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0576 - accuracy: 0.9827 - val_loss: 3.6444 - val_accuracy: 0.6368\n","Epoch 155/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0894 - accuracy: 0.9764 - val_loss: 3.5121 - val_accuracy: 0.6179\n","Epoch 156/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0598 - accuracy: 0.9780 - val_loss: 3.7829 - val_accuracy: 0.6274\n","Epoch 157/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0698 - accuracy: 0.9780 - val_loss: 3.9828 - val_accuracy: 0.6368\n","Epoch 158/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0906 - accuracy: 0.9827 - val_loss: 3.8474 - val_accuracy: 0.6557\n","Epoch 159/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1129 - accuracy: 0.9623 - val_loss: 3.6031 - val_accuracy: 0.6226\n","Epoch 160/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1098 - accuracy: 0.9623 - val_loss: 4.2992 - val_accuracy: 0.5896\n","Epoch 161/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1191 - accuracy: 0.9623 - val_loss: 4.0855 - val_accuracy: 0.6132\n","Epoch 162/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0616 - accuracy: 0.9811 - val_loss: 4.3035 - val_accuracy: 0.5943\n","Epoch 163/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1184 - accuracy: 0.9748 - val_loss: 3.5226 - val_accuracy: 0.6132\n","Epoch 164/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1163 - accuracy: 0.9591 - val_loss: 3.6526 - val_accuracy: 0.5943\n","Epoch 165/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0746 - accuracy: 0.9748 - val_loss: 3.6733 - val_accuracy: 0.5802\n","Epoch 166/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0507 - accuracy: 0.9827 - val_loss: 4.0576 - val_accuracy: 0.6132\n","Epoch 167/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0697 - accuracy: 0.9748 - val_loss: 3.8770 - val_accuracy: 0.6226\n","Epoch 168/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0484 - accuracy: 0.9890 - val_loss: 4.1046 - val_accuracy: 0.6415\n","Epoch 169/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 4.1141 - val_accuracy: 0.6132\n","Epoch 170/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0509 - accuracy: 0.9796 - val_loss: 3.9998 - val_accuracy: 0.6085\n","Epoch 171/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0386 - accuracy: 0.9921 - val_loss: 4.2113 - val_accuracy: 0.6274\n","Epoch 172/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0958 - accuracy: 0.9686 - val_loss: 4.1471 - val_accuracy: 0.6226\n","Epoch 173/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 5.3295 - val_accuracy: 0.6085\n","Epoch 174/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1280 - accuracy: 0.9748 - val_loss: 4.2931 - val_accuracy: 0.6179\n","Epoch 175/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0618 - accuracy: 0.9843 - val_loss: 4.4394 - val_accuracy: 0.6038\n","Epoch 176/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.1195 - accuracy: 0.9780 - val_loss: 3.8312 - val_accuracy: 0.5943\n","Epoch 177/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0466 - accuracy: 0.9843 - val_loss: 4.0538 - val_accuracy: 0.6226\n","Epoch 178/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0496 - accuracy: 0.9843 - val_loss: 4.2240 - val_accuracy: 0.6274\n","Epoch 179/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0463 - accuracy: 0.9858 - val_loss: 4.6994 - val_accuracy: 0.5849\n","Epoch 180/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0338 - accuracy: 0.9858 - val_loss: 4.5286 - val_accuracy: 0.5991\n","Epoch 181/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0608 - accuracy: 0.9843 - val_loss: 4.5401 - val_accuracy: 0.5849\n","Epoch 182/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0572 - accuracy: 0.9827 - val_loss: 4.2996 - val_accuracy: 0.6226\n","Epoch 183/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0559 - accuracy: 0.9827 - val_loss: 4.2856 - val_accuracy: 0.6274\n","Epoch 184/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0505 - accuracy: 0.9874 - val_loss: 4.7017 - val_accuracy: 0.6274\n","Epoch 185/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0868 - accuracy: 0.9764 - val_loss: 4.3822 - val_accuracy: 0.6274\n","Epoch 186/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.1053 - accuracy: 0.9733 - val_loss: 4.0241 - val_accuracy: 0.6226\n","Epoch 187/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0835 - accuracy: 0.9717 - val_loss: 4.1356 - val_accuracy: 0.6462\n","Epoch 188/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0277 - accuracy: 0.9874 - val_loss: 4.2287 - val_accuracy: 0.6226\n","Epoch 189/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0916 - accuracy: 0.9827 - val_loss: 4.0840 - val_accuracy: 0.6604\n","Epoch 190/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0803 - accuracy: 0.9780 - val_loss: 4.3790 - val_accuracy: 0.6179\n","Epoch 191/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0586 - accuracy: 0.9796 - val_loss: 4.4238 - val_accuracy: 0.6179\n","Epoch 192/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0822 - accuracy: 0.9780 - val_loss: 4.3515 - val_accuracy: 0.6274\n","Epoch 193/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0646 - accuracy: 0.9748 - val_loss: 4.2709 - val_accuracy: 0.6321\n","Epoch 194/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0629 - accuracy: 0.9780 - val_loss: 4.1461 - val_accuracy: 0.6274\n","Epoch 195/200\n","80/80 [==============================] - 3s 38ms/step - loss: 0.0306 - accuracy: 0.9874 - val_loss: 4.2978 - val_accuracy: 0.6132\n","Epoch 196/200\n","80/80 [==============================] - 3s 36ms/step - loss: 0.0584 - accuracy: 0.9843 - val_loss: 4.5489 - val_accuracy: 0.6509\n","Epoch 197/200\n","80/80 [==============================] - 4s 51ms/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 4.4226 - val_accuracy: 0.6415\n","Epoch 198/200\n","80/80 [==============================] - 4s 47ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 4.4430 - val_accuracy: 0.6415\n","Epoch 199/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0321 - accuracy: 0.9906 - val_loss: 4.3143 - val_accuracy: 0.6462\n","Epoch 200/200\n","80/80 [==============================] - 3s 37ms/step - loss: 0.0335 - accuracy: 0.9843 - val_loss: 4.3002 - val_accuracy: 0.6321\n"]}]},{"cell_type":"code","source":["# demonstration of calculating metrics for a neural network model using sklearn\n","from sklearn.datasets import make_circles\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n"],"metadata":{"id":"x40eSRtiljvE","executionInfo":{"status":"ok","timestamp":1663136024398,"user_tz":-360,"elapsed":6,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["yhat_probs = model.predict(x_test, verbose=0)\n","yhat_probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWIiGXxxlkuU","executionInfo":{"status":"ok","timestamp":1663137050846,"user_tz":-360,"elapsed":428,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"c2976dc2-8ab7-4d69-ebb2-509d334d39f4"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.00000000e+00, 2.37344391e-22, 2.31887635e-24, 1.71256774e-16],\n","       [7.39076811e-17, 1.00000000e+00, 3.79235586e-25, 2.76019548e-21],\n","       [2.59773092e-08, 1.98038430e-09, 9.99030709e-01, 9.69246670e-04],\n","       [6.17847177e-15, 7.35760108e-03, 9.89091992e-01, 3.55032110e-03],\n","       [9.99975324e-01, 2.47172029e-05, 1.19774147e-29, 1.87922833e-08],\n","       [9.99997973e-01, 5.09250100e-08, 1.23825124e-17, 2.03303284e-06],\n","       [2.34029629e-24, 9.99894500e-01, 6.86353451e-05, 3.68033943e-05],\n","       [1.26670580e-15, 1.00000000e+00, 9.61897767e-20, 3.80155551e-09],\n","       [4.25582874e-20, 3.74303758e-01, 6.25695884e-01, 3.76403534e-07],\n","       [1.23437244e-13, 4.72903956e-08, 8.41266093e-15, 1.00000000e+00],\n","       [6.43618107e-01, 1.78010881e-01, 1.57300874e-05, 1.78355336e-01],\n","       [2.01064118e-04, 9.78236973e-01, 2.73424547e-11, 2.15620380e-02],\n","       [1.00000000e+00, 4.28285046e-18, 2.96033820e-24, 8.03414668e-10],\n","       [1.00000000e+00, 1.28982229e-24, 0.00000000e+00, 5.75891724e-19],\n","       [8.15071601e-08, 1.86720819e-04, 2.51896358e-06, 9.99810755e-01],\n","       [1.00000000e+00, 3.45048290e-22, 0.00000000e+00, 1.41940504e-17],\n","       [1.00000000e+00, 2.78360317e-38, 0.00000000e+00, 3.91482746e-18],\n","       [1.50088262e-13, 2.16357829e-08, 6.59647822e-01, 3.40352237e-01],\n","       [2.75546972e-30, 5.01806525e-08, 1.00000000e+00, 2.09418298e-13],\n","       [9.99977231e-01, 1.83971570e-05, 1.80061907e-16, 4.38503230e-06],\n","       [1.04845047e-03, 9.54237342e-01, 5.84290603e-07, 4.47136164e-02],\n","       [2.15204927e-04, 8.26433973e-12, 0.00000000e+00, 9.99784768e-01],\n","       [9.99875307e-01, 3.79367266e-05, 3.76479761e-06, 8.30044155e-05],\n","       [5.00111957e-04, 1.58710871e-02, 2.62927529e-08, 9.83628690e-01],\n","       [3.62245803e-04, 1.64627338e-07, 8.12375173e-03, 9.91513908e-01],\n","       [2.36231774e-01, 1.45871535e-01, 9.39817889e-16, 6.17896676e-01],\n","       [8.57103586e-01, 4.63413983e-07, 6.25073561e-13, 1.42895907e-01],\n","       [8.17958765e-13, 2.51787957e-13, 1.02574359e-29, 1.00000000e+00],\n","       [1.47234732e-06, 9.99814212e-01, 4.79630181e-12, 1.84325705e-04],\n","       [4.48188018e-07, 9.99999523e-01, 1.26961067e-18, 3.50926310e-09],\n","       [1.12818474e-33, 8.93911783e-05, 9.99910593e-01, 3.36839267e-19],\n","       [3.12017800e-14, 2.08774765e-07, 9.99999642e-01, 1.28521734e-07],\n","       [2.79097289e-01, 1.48664322e-03, 9.71933342e-21, 7.19416022e-01],\n","       [8.54733385e-13, 9.43982392e-04, 6.79753900e-01, 3.19302201e-01],\n","       [4.26764553e-03, 9.20812488e-01, 1.71873751e-10, 7.49199614e-02],\n","       [1.01821085e-13, 1.06637925e-03, 5.78581457e-05, 9.98875797e-01],\n","       [1.00000000e+00, 4.87118287e-28, 6.06582911e-34, 3.50165424e-10],\n","       [8.51573125e-02, 2.91886460e-02, 2.14981453e-11, 8.85654092e-01],\n","       [1.00000000e+00, 5.06094766e-33, 0.00000000e+00, 9.06444794e-32],\n","       [1.00000000e+00, 1.34604120e-13, 0.00000000e+00, 3.33426364e-12],\n","       [1.66552419e-17, 6.07630391e-05, 9.99925256e-01, 1.39005706e-05],\n","       [3.90068955e-09, 1.56795722e-05, 9.99984264e-01, 1.46652424e-09],\n","       [2.00027863e-23, 1.68573024e-07, 9.99999881e-01, 4.32006167e-12],\n","       [7.81558498e-11, 1.99261422e-07, 9.99999762e-01, 8.07715583e-09],\n","       [1.51489411e-11, 2.46895922e-07, 4.18055180e-07, 9.99999285e-01],\n","       [1.00000000e+00, 1.21746701e-17, 1.50335857e-26, 1.37958039e-11],\n","       [8.27730062e-09, 1.67218275e-07, 9.99999881e-01, 7.74117659e-09],\n","       [9.82504571e-04, 3.44940811e-01, 4.14526441e-10, 6.54076695e-01],\n","       [4.55694336e-11, 2.11630089e-04, 9.99787152e-01, 1.23537427e-06],\n","       [3.12893023e-09, 3.39888901e-01, 4.22589213e-01, 2.37521872e-01],\n","       [2.68377539e-06, 4.28354070e-07, 4.99244332e-02, 9.50072467e-01],\n","       [1.00000000e+00, 4.75349218e-08, 1.62595643e-36, 1.00862108e-13],\n","       [9.04349963e-06, 9.52426493e-01, 1.24592129e-02, 3.51052247e-02],\n","       [1.87305683e-14, 4.27032679e-01, 5.72967350e-01, 1.18296151e-10],\n","       [1.00000000e+00, 8.19815618e-36, 1.40830792e-36, 7.81702391e-32],\n","       [5.73773111e-26, 9.99995232e-01, 4.58989416e-06, 1.39105467e-07],\n","       [4.13063819e-11, 1.67966631e-04, 9.99763072e-01, 6.90329034e-05],\n","       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n","       [9.70808944e-09, 4.13548662e-07, 3.33954975e-09, 9.99999523e-01],\n","       [9.99837160e-01, 2.19885984e-10, 1.03648813e-34, 1.62854849e-04],\n","       [9.99995708e-01, 1.24155497e-09, 6.93709489e-27, 4.34899312e-06],\n","       [4.80825931e-23, 2.35163213e-16, 1.00000000e+00, 6.07841414e-13],\n","       [6.44814101e-16, 1.14685290e-12, 1.00000000e+00, 1.30543396e-10],\n","       [4.74289182e-19, 9.20818806e-01, 7.91811869e-02, 7.28608107e-09],\n","       [3.83620024e-01, 1.03652790e-04, 1.94462244e-23, 6.16276324e-01],\n","       [5.07381499e-01, 4.90280718e-01, 2.00797536e-13, 2.33780523e-03],\n","       [1.99105955e-07, 4.10406627e-02, 8.50196838e-01, 1.08762413e-01],\n","       [4.06112940e-06, 1.43965619e-04, 9.99717414e-01, 1.34557966e-04],\n","       [1.57098675e-05, 2.52922965e-12, 6.52620953e-17, 9.99984264e-01],\n","       [5.11831462e-01, 1.79001314e-09, 1.63185534e-22, 4.88168538e-01],\n","       [1.41428346e-14, 3.33464528e-12, 1.00000000e+00, 3.73114067e-10],\n","       [4.53739762e-01, 1.98780242e-10, 2.39052992e-27, 5.46260238e-01],\n","       [5.36013365e-01, 1.79327220e-01, 2.19027504e-01, 6.56319484e-02],\n","       [3.24938974e-08, 7.38804578e-04, 6.37879908e-01, 3.61381322e-01],\n","       [3.60465707e-18, 1.48520917e-01, 8.51479113e-01, 9.42462497e-11],\n","       [1.78169343e-03, 2.68381359e-06, 6.91749892e-06, 9.98208761e-01],\n","       [2.62169038e-07, 9.08254805e-09, 9.99999404e-01, 3.88111545e-07],\n","       [4.37599084e-07, 9.60438013e-01, 2.11256619e-07, 3.95612754e-02],\n","       [9.34339550e-11, 2.28546360e-05, 9.98161972e-01, 1.81525340e-03],\n","       [5.83978444e-02, 2.25581258e-04, 3.95671239e-11, 9.41376626e-01],\n","       [1.25922450e-09, 2.53334815e-06, 5.59592025e-11, 9.99997497e-01],\n","       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n","       [1.83617685e-14, 1.27507614e-11, 7.69675038e-15, 1.00000000e+00],\n","       [5.54656894e-17, 2.29460158e-14, 1.00000000e+00, 1.16521867e-14],\n","       [3.04314108e-06, 1.77178619e-04, 1.32295099e-05, 9.99806583e-01],\n","       [1.93662430e-07, 9.79662687e-02, 8.55080485e-01, 4.69530299e-02],\n","       [1.15596328e-27, 2.09069403e-04, 9.99790967e-01, 2.76059991e-12],\n","       [8.97476266e-14, 7.95979371e-09, 1.00000000e+00, 4.75813664e-08],\n","       [1.94828945e-11, 4.91166065e-06, 9.99217749e-01, 7.77391891e-04],\n","       [1.42261921e-13, 9.99999762e-01, 4.97779136e-18, 2.96838067e-07],\n","       [7.53168986e-11, 8.28808061e-06, 4.58663404e-01, 5.41328251e-01],\n","       [8.17763507e-01, 1.84591091e-03, 1.14784548e-02, 1.68912143e-01],\n","       [9.99928594e-01, 4.53388611e-06, 5.28978562e-05, 1.39479171e-05],\n","       [1.23389195e-16, 9.99999404e-01, 4.46041923e-07, 6.13426110e-08],\n","       [1.58744860e-12, 1.79796608e-10, 9.98390317e-01, 1.60966604e-03],\n","       [2.24919223e-15, 1.08069224e-04, 9.99883175e-01, 8.72378405e-06],\n","       [5.97135658e-26, 1.00000000e+00, 2.09592411e-29, 6.61970885e-14],\n","       [3.33366042e-04, 9.98174429e-01, 2.56186254e-08, 1.49212917e-03],\n","       [2.16720361e-17, 2.27185319e-06, 9.99997377e-01, 3.31189256e-07],\n","       [2.71911587e-04, 1.67453184e-03, 1.83948447e-04, 9.97869611e-01],\n","       [7.77948940e-15, 2.81261993e-12, 1.00000000e+00, 1.05907878e-08],\n","       [3.01332663e-26, 1.71164348e-20, 2.37938041e-38, 1.00000000e+00],\n","       [1.08637676e-14, 2.10644675e-08, 1.00000000e+00, 3.38258089e-12],\n","       [1.59491342e-03, 1.25877181e-04, 2.68993992e-02, 9.71379817e-01],\n","       [3.44503626e-08, 2.32415716e-03, 9.97675717e-01, 7.90624810e-08],\n","       [2.97390470e-05, 2.51613379e-01, 6.35221228e-03, 7.42004693e-01],\n","       [9.99999642e-01, 8.23801827e-09, 6.92280122e-25, 3.99694500e-07],\n","       [1.31711372e-25, 1.00000000e+00, 7.61188722e-33, 6.59739243e-27],\n","       [1.06469296e-01, 6.42997387e-04, 1.21012062e-03, 8.91677558e-01],\n","       [2.65355825e-21, 4.80925519e-06, 9.99986649e-01, 8.58794101e-06],\n","       [3.13713457e-07, 9.97705162e-01, 2.29320885e-03, 1.35828475e-06],\n","       [1.41053231e-08, 8.54381756e-12, 9.98279486e-34, 1.00000000e+00],\n","       [1.57556897e-05, 9.99650598e-01, 3.06320544e-05, 3.03081586e-04],\n","       [5.96098415e-09, 5.12552112e-10, 7.43861068e-21, 1.00000000e+00],\n","       [5.34019666e-04, 2.07396951e-07, 1.57506029e-12, 9.99465764e-01],\n","       [5.21466171e-13, 5.16793597e-03, 9.94794309e-01, 3.77587421e-05],\n","       [9.69597624e-10, 2.39927729e-04, 9.47430253e-01, 5.23298755e-02],\n","       [3.01129990e-06, 9.99984622e-01, 3.51252969e-29, 1.23627533e-05],\n","       [7.25163400e-01, 4.97138259e-08, 2.74831265e-01, 5.29194858e-06],\n","       [2.23164484e-14, 9.89934623e-01, 1.00565515e-02, 8.82163295e-06],\n","       [2.49700000e-12, 2.69187469e-04, 9.99728978e-01, 1.74287959e-06],\n","       [9.98220265e-01, 1.77862064e-03, 4.66430087e-19, 1.10014378e-06],\n","       [4.35705809e-03, 9.56781566e-01, 9.10063318e-06, 3.88522819e-02],\n","       [2.14452683e-07, 9.53451172e-02, 2.23805457e-01, 6.80849195e-01],\n","       [2.53997906e-10, 4.35121910e-05, 1.92525389e-03, 9.98031199e-01],\n","       [1.17067626e-04, 6.42520050e-03, 1.09262623e-19, 9.93457735e-01],\n","       [1.76868561e-10, 1.19982518e-01, 2.01512956e-11, 8.80017459e-01],\n","       [2.13053492e-10, 1.25150437e-11, 1.00000000e+00, 3.57338381e-09],\n","       [4.46521119e-12, 1.00000000e+00, 4.62878766e-08, 1.38131104e-10],\n","       [5.01981319e-08, 5.12832950e-04, 2.57053562e-05, 9.99461472e-01],\n","       [9.99976516e-01, 5.98717497e-06, 3.04521518e-13, 1.75695659e-05],\n","       [8.22013901e-10, 1.06982187e-10, 1.22110302e-19, 1.00000000e+00],\n","       [2.17233683e-04, 8.69269252e-01, 2.79315165e-03, 1.27720490e-01],\n","       [3.75904664e-02, 3.26867048e-05, 4.96029224e-06, 9.62371886e-01],\n","       [9.16668214e-03, 8.74135367e-07, 3.71001589e-18, 9.90832388e-01],\n","       [9.08687268e-19, 3.16338379e-14, 1.00000000e+00, 6.07380967e-14],\n","       [6.45509213e-21, 3.45529998e-06, 9.99996543e-01, 7.33414111e-12],\n","       [1.04157853e-05, 2.00114783e-07, 3.75192872e-06, 9.99985576e-01],\n","       [2.94781064e-17, 7.38741411e-03, 9.92594182e-01, 1.84012515e-05],\n","       [1.61824487e-18, 2.18900514e-05, 1.58445537e-02, 9.84133601e-01],\n","       [4.07909421e-04, 1.47528261e-01, 5.94561577e-01, 2.57502288e-01],\n","       [4.33681453e-05, 5.56448964e-17, 0.00000000e+00, 9.99956608e-01],\n","       [1.67294061e-11, 9.65400322e-05, 9.99461472e-01, 4.42037359e-04],\n","       [2.27886499e-04, 9.22543943e-01, 2.98135819e-06, 7.72252604e-02],\n","       [1.22924906e-03, 6.22473732e-02, 3.58537585e-01, 5.77985764e-01],\n","       [9.09098439e-15, 9.98037517e-01, 1.91324716e-03, 4.92313739e-05],\n","       [2.62973637e-17, 1.38608630e-16, 1.00000000e+00, 3.59413779e-12],\n","       [1.78545525e-12, 1.00000000e+00, 6.82319087e-28, 6.04209198e-18],\n","       [2.05616644e-07, 9.90933537e-01, 1.78835016e-10, 9.06624831e-03],\n","       [2.47684042e-08, 4.02852078e-04, 3.23376116e-05, 9.99564826e-01],\n","       [4.31907754e-09, 9.98617411e-01, 2.70378291e-06, 1.37989491e-03],\n","       [3.03136612e-13, 7.00736709e-04, 9.89239573e-01, 1.00597460e-02],\n","       [1.00000000e+00, 1.00298086e-13, 2.77233579e-25, 1.12460592e-13],\n","       [1.00000000e+00, 2.10359508e-09, 0.00000000e+00, 9.96652272e-09],\n","       [9.66776583e-31, 2.49677107e-01, 7.50322878e-01, 9.98047593e-16],\n","       [1.98463274e-10, 1.12425704e-02, 9.88744497e-01, 1.29914642e-05],\n","       [2.61909213e-06, 9.19318332e-13, 3.51938835e-14, 9.99997377e-01],\n","       [2.78940049e-09, 2.99079660e-02, 4.62558359e-01, 5.07533729e-01],\n","       [2.39768222e-01, 2.94452824e-04, 7.06943592e-06, 7.59930253e-01],\n","       [4.64593060e-03, 7.62338098e-03, 1.81007707e-08, 9.87730682e-01],\n","       [4.90311874e-21, 3.59040177e-06, 9.99996424e-01, 1.95882425e-15],\n","       [8.50704242e-15, 3.40166688e-02, 8.35280865e-02, 8.82455230e-01],\n","       [1.00000000e+00, 1.21581641e-22, 0.00000000e+00, 1.81401643e-14],\n","       [3.79852167e-07, 1.13160175e-04, 3.32393597e-08, 9.99886394e-01],\n","       [2.34683328e-10, 9.61491346e-01, 1.45449629e-03, 3.70542146e-02],\n","       [4.41921239e-12, 3.43292299e-07, 2.49511591e-04, 9.99750197e-01],\n","       [2.17996905e-11, 1.97814796e-02, 9.41163778e-01, 3.90547104e-02],\n","       [2.28874515e-12, 1.21517924e-05, 9.99987841e-01, 2.02401047e-08],\n","       [1.41106946e-10, 2.03859192e-04, 9.91436779e-01, 8.35933443e-03],\n","       [1.11859456e-13, 5.30009326e-23, 0.00000000e+00, 1.00000000e+00],\n","       [4.83568874e-06, 9.98808384e-01, 8.41569090e-08, 1.18664652e-03],\n","       [1.84682658e-10, 7.00295786e-08, 3.60339880e-02, 9.63965952e-01],\n","       [7.38345832e-02, 4.52864394e-02, 1.05087695e-23, 8.80878985e-01],\n","       [4.23772875e-08, 2.98432042e-06, 3.12386610e-11, 9.99997020e-01],\n","       [1.00000000e+00, 2.74431877e-15, 1.16184489e-30, 3.22886147e-17],\n","       [1.00000000e+00, 6.70135446e-22, 7.80900219e-33, 1.17482305e-15],\n","       [2.26816734e-32, 1.76494766e-03, 9.98234987e-01, 8.29261166e-20],\n","       [3.65695837e-06, 4.08363621e-12, 6.91232290e-19, 9.99996305e-01],\n","       [1.00000000e+00, 3.27067206e-34, 0.00000000e+00, 1.15416853e-28],\n","       [1.00000000e+00, 5.29215716e-14, 2.19042416e-16, 1.01615868e-11],\n","       [4.95258608e-12, 1.33704215e-01, 8.40889871e-01, 2.54059490e-02],\n","       [4.10808047e-04, 3.96276903e-07, 9.99587357e-01, 1.47645335e-06],\n","       [5.41694171e-05, 6.94513088e-03, 2.15771465e-07, 9.93000507e-01],\n","       [2.43187763e-08, 9.84121929e-04, 9.98387337e-01, 6.28523936e-04],\n","       [8.88199687e-01, 5.17125381e-03, 9.87917483e-02, 7.83736259e-03],\n","       [1.26030644e-08, 6.84613883e-02, 9.68993644e-25, 9.31538641e-01],\n","       [1.67256843e-07, 1.81467636e-11, 1.26759216e-08, 9.99999762e-01],\n","       [4.97509412e-12, 1.48111203e-05, 6.54356321e-04, 9.99330878e-01],\n","       [6.68972725e-17, 2.79737681e-01, 4.14363870e-22, 7.20262289e-01],\n","       [1.50065100e-15, 4.20519565e-12, 1.37023968e-18, 1.00000000e+00],\n","       [3.45247933e-20, 9.99982357e-01, 1.76793583e-05, 2.93933429e-16],\n","       [1.23723922e-11, 3.13200843e-09, 9.99999285e-01, 6.63441597e-07],\n","       [2.38082148e-19, 9.99985456e-01, 1.44048636e-05, 1.20302857e-07],\n","       [5.61650880e-18, 2.89045165e-15, 1.00000000e+00, 8.64238260e-13],\n","       [2.23392399e-05, 9.99240875e-01, 2.06974846e-06, 7.34775502e-04],\n","       [9.99997735e-01, 9.22491893e-07, 1.18867946e-20, 1.30569629e-06],\n","       [5.28634570e-21, 2.34077220e-07, 9.99999642e-01, 6.45817266e-08],\n","       [3.15323317e-18, 1.00000000e+00, 3.07451953e-10, 6.17338750e-11],\n","       [1.03938202e-09, 6.29748851e-02, 9.32116151e-01, 4.90905251e-03],\n","       [9.99731600e-01, 5.35773097e-06, 5.20943357e-19, 2.63004360e-04],\n","       [1.99726007e-15, 1.18707440e-11, 1.00000000e+00, 3.37123254e-08],\n","       [2.34853105e-05, 9.99974608e-01, 1.37274789e-10, 1.92554626e-06],\n","       [5.11557209e-06, 9.99990940e-01, 1.85348128e-08, 3.97165604e-06],\n","       [5.74494123e-08, 9.99748647e-01, 4.17517185e-08, 2.51389487e-04],\n","       [1.55824423e-01, 3.29680800e-01, 2.42364231e-14, 5.14494777e-01],\n","       [4.39107257e-11, 9.88671303e-01, 1.68803701e-04, 1.11599257e-02],\n","       [7.97822118e-01, 5.63636161e-02, 1.80373458e-08, 1.45814225e-01],\n","       [4.95242476e-12, 1.49687929e-02, 9.85029161e-01, 1.96892256e-06],\n","       [8.24692718e-17, 9.99997497e-01, 1.75037621e-06, 7.32772833e-07],\n","       [2.33415037e-01, 2.68650765e-05, 1.55085181e-11, 7.66558111e-01],\n","       [4.44696282e-13, 1.23957107e-02, 9.87568021e-01, 3.62027968e-05],\n","       [9.15152502e-13, 9.99857903e-01, 1.42046527e-04, 1.74445214e-09]],\n","      dtype=float32)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["yhat_classes = model.predict_classes(x_test, verbose=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"saSHrzslojrT","executionInfo":{"status":"error","timestamp":1663136097041,"user_tz":-360,"elapsed":379,"user":{"displayName":"Ahmed Rafi Hasan","userId":"13961549991423405694"}},"outputId":"6b0cdbb5-cc2b-430e-c5b1-9bf4ef87dd48"},"execution_count":18,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-49bb74327cbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myhat_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"]}]}]}